# Xulosa

Ushbu bobda fundamental modelni yaratishdagi asosiy dizayn qarorlari muhokama qilindi. Aksariyat odamlar modelni noldan o'qitish o'rniga tayyor fundamental modellardan foydalanishlarini hisobga olib, men qaysi modellarni ishlatish va ulardan qanday foydalanishni hal qilishga yordam beradigan modellashtirish omillari foydasiga mayda-chuyda o'qitish tafsilotlarini o'tkazib yubordim.

Model samaradorligiga ta'sir qiluvchi hal qiluvchi omil — bu uning o'qitish ma'lumotlaridir. Katta modellar katta hajmdagi o'qitish ma'lumotlarini talab qiladi, ularni olish esa qimmat va ko'p vaqt talab qilishi mumkin. Shu sababli, model provayderlari ko'pincha mavjud bo'lgan har qanday ma'lumotlardan foydalanishadi. Bu esa o'qitish ma'lumotlarida mavjud bo'lgan ko'plab vazifalarda yaxshi ishlaydigan, lekin siz xohlagan maxsus vazifani o'z ichiga olmasligi mumkin bo'lgan modellarni keltirib chiqaradi. Ushbu bobda nima uchun maxsus tillarga, ayniqsa kam resursli tillarga va maxsus sohalarga mo'ljallangan modellarni ishlab chiqish uchun o'qitish ma'lumotlarini saralash ko'pincha zarur ekanligi ko'rib chiqildi.

Ma'lumotlarni topgandan so'ng, modelni ishlab chiqish boshlanishi mumkin. Garchi modelni o'qitish ko'pincha sarlavhalarda ustunlik qilsa-da, undan oldingi muhim qadam — bu modelni arxitekturalashdir. Bobda model arxitekturasi va model hajmi kabi modellashtirish tanlovlari ko'rib chiqildi. Tilga asoslangan fundamental modellar uchun hukmron arxitektura — bu Transformer'dir. Ushbu bobda Transformer arxitekturasi hal qilish uchun ishlab chiqilgan muammolar, shuningdek, uning cheklovlari o'rganildi.

Modelning miqyosini uchta asosiy raqam bilan o'lchash mumkin: parametrlar soni, o'qitish tokenlari soni va o'qitish uchun zarur bo'lgan _FLOP_'lar soni. Modelni o'qitish uchun zarur bo'lgan hisoblash hajmiga ta'sir qiluvchi ikki jihat — bu model hajmi va ma'lumotlar hajmidir. Miqyoslash qonuni hisoblash byudjeti berilganda optimal parametrlar sonini va tokenlar sonini aniqlashga yordam beradi. Ushbu bobda, shuningdek, miqyoslashdagi to'siqlar ham ko'rib chiqildi. Hozirda modelni kattalashtirish odatda uni yaxshiroq qiladi. Ammo bu qachongacha davom etadi?

Dastlabki o'qitish paytidagi past sifatli o'qitish ma'lumotlari va o'z-o'zini nazorat qilish tufayli, natijaviy model foydalanuvchilar xohlagan narsaga mos kelmaydigan natijalar chiqarishi mumkin. Bu muammo yakuniy o'qitish orqali hal qilinadi, u ikki bosqichdan iborat: nazoratli qo'shimcha sozlash va ma'qullash asosida sozlash. Inson afzalliklari xilma-xil va ularni yagona matematik formulada aks ettirish imkonsiz, shuning uchun mavjud yechimlar mukammallikdan yiroq.

Ushbu bob, shuningdek, mening sevimli mavzularimdan birini qamrab oldi: _sampling_ — modelning chiqish tokenlarini generatsiya qilish jarayoni. _Sampling_ SI modellarini ehtimoliy qiladi. Aynan shu ehtimoliy tabiat `ChatGPT` va `Gemini` kabi modellarni ijodiy vazifalar uchun ajoyib va suhbatlashish uchun maroqli qiladi. Biroq, bu ehtimoliy tabiat barqarorsizlik va gallyutsinatsiyalarga ham sabab bo'ladi.

SI modellari bilan ishlash o'z ish jarayonlaringizni ularning ehtimoliy tabiati atrofida qurishni talab qiladi. Ushbu kitobning qolgan qismi SI muhandisligini, agar deterministik bo'lmasa ham, hech bo'lmaganda tizimli qilishni o'rganadi. Tizimli SI muhandisligi sari birinchi qadam — bu nosozliklar va kutilmagan o'zgarishlarni aniqlashga yordam beradigan mustahkam baholash jarayonlari ketma-ketligini (`evaluation pipeline`) o'rnatishdir. Fundamental modellar uchun baholash shu qadar muhimki, men unga ikkita butun bobni bag'ishladim va keyingi bobdan boshlaymiz.