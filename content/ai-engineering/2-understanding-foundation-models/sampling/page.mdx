# Sampling

Model o'z natijalarini _sampling_ (ya'ni, ehtimolliklar taqsimoti asosida natijani tanlab olish) deb nomlanuvchi jarayon orqali quradi. Ushbu bo'lim turli _sampling_ strategiyalari va _sampling_ parametrlarini, jumladan, harorat (`temperature`), `top-k` va `top-p`'ni muhokama qiladi. Keyin u model samaradorligini oshirish uchun bir nechta natijani qanday _sampling_ qilishni o'rganadi. Shuningdek, biz _sampling_ jarayonini modellarni ma'lum formatlar va cheklovlarga rioya qiladigan javoblarni generatsiya qilishga undash uchun qanday o'zgartirish mumkinligini ko'rib chiqamiz.

_Sampling_ SI natijalarini ehtimoliy qiladi. Bu ehtimoliy tabiatni tushunish SI'ning barqarorsizlik va gallyutsinatsiya kabi xatti-harakatlarini boshqarish uchun muhimdir. Ushbu bo'lim bu ehtimoliy tabiat nimani anglatishi va u bilan qanday ishlash kerakligini chuqur o'rganish bilan yakunlanadi.

## _Sampling_ asoslari

Kirish ma'lumoti berilganda, neyron to'r avval ehtimoliy natijalarning ehtimolliklarini hisoblab, keyin natija chiqaradi. Tasniflash modeli uchun ehtimoliy natijalar — bu mavjud sinflardir. Misol uchun, agar model elektron pochtaning spam yoki spam emasligini tasniflashga o'qitilgan bo'lsa, faqat ikkita ehtimoliy natija mavjud: spam va spam emas. Model ushbu ikki natijaning har birining ehtimolligini hisoblaydi — masalan, elektron pochtaning spam bo'lish ehtimoli 90%, spam bo'lmaslik ehtimoli esa 10%. Keyin siz ushbu chiqish ehtimolliklariga asoslanib qaror qabul qilishingiz mumkin. Masalan, agar siz spam ehtimoli 50% dan yuqori bo'lgan har qanday elektron pochta spam deb belgilanishi kerak deb qaror qilsangiz, 90% spam ehtimoliga ega bo'lgan elektron pochta spam deb belgilanadi.

Til modeli uchun, keyingi tokenni generatsiya qilish uchun, model avval lug'atdagi barcha tokenlar bo'yicha ehtimollik taqsimotini hisoblaydi, bu 2-14-rasmda ko'rsatilgan.

![2-14-rasm. Keyingi tokenni generatsiya qilish uchun til modeli avval lug'atdagi barcha tokenlar bo'yicha ehtimollik taqsimotini hisoblaydi.](/ai-engineering/2-chapter/2.14-figure.png)

<div className='text-center text-sm italic'>2-14-rasm. Keyingi tokenni generatsiya qilish uchun til modeli avval lug'atdagi barcha tokenlar bo'yicha ehtimollik taqsimotini hisoblaydi.</div>

Turli ehtimolliklarga ega bo'lgan ehtimoliy natijalar bilan ishlaganda, keng tarqalgan strategiya eng yuqori ehtimollikka ega bo'lgan natijani tanlashdir. Har doim eng ehtimolli natijani tanlash **ochko'z _sampling_** (`greedy sampling`) deb ataladi. Bu ko'pincha tasniflash vazifalari uchun ishlaydi. Masalan, agar model elektron pochtaning spam bo'lmasligidan ko'ra spam bo'lish ehtimoli yuqoriroq deb hisoblasa, uni spam deb belgilash mantiqan to'g'ri. Biroq, til modeli uchun ochko'z _sampling_ zerikarli natijalar yaratadi. Tasavvur qiling, siz qanday savol berishingizdan qat'i nazar, doimo eng keng tarqalgan so'zlar bilan javob beradigan modelni.

Har doim keyingi eng ehtimolli tokenni tanlash o'rniga, model keyingi tokenni barcha mumkin bo'lgan qiymatlar bo'yicha ehtimollik taqsimotiga muvofiq _sampling_ qilishi mumkin. 2-14-rasmda ko'rsatilganidek, "Mening sevimli rangim ..." konteksti berilganda, agar "qizil"ning keyingi token bo'lish ehtimoli 30% va "yashil"ning ehtimoli 50% bo'lsa, "qizil" 30% hollarda, "yashil" esa 50% hollarda tanlanadi.

Model bu ehtimolliklarni qanday hisoblaydi? Kirish ma'lumoti berilganda, neyron to'r _logit_ vektorini (ehtimollikka aylantirilmagan "xom" ballar vektorini) chiqaradi. Har bir _logit_ bitta ehtimoliy qiymatga mos keladi. Til modeli misolida, har bir _logit_ model lug'atidagi bitta tokenga mos keladi. _Logit_ vektorining o'lchami lug'at hajmiga teng. _Logit_ vektorining vizualizatsiyasi 2-15-rasmda ko'rsatilgan.

![2-15-rasm. Har bir kirish uchun til modeli logit vektorini hosil qiladi. Har bir logit lug'atdagi bir tokenga mos keladi.](/ai-engineering/2-chapter/2.15-figure.png)

<div className='text-center text-sm italic'>2-15-rasm. Har bir kirish uchun til modeli _logit_ vektorini hosil qiladi. Har bir _logit_ lug'atdagi bir tokenga mos keladi.</div>

Kattaroq _logit_'lar yuqori ehtimolliklarga mos kelsa-da, _logit_'lar ehtimolliklarni ifodalamaydi. _Logit_'lar yig'indisi birga teng emas. _Logit_'lar hatto manfiy bo'lishi ham mumkin, ehtimolliklar esa manfiy bo'lmasligi kerak. _Logit_'larni ehtimolliklarga aylantirish uchun ko'pincha `softmax` qatlami ishlatiladi. Aytaylik, model N hajmli lug'atga ega va _logit_ vektori _[_x_<sub>1</sub>, _x_<sub>2</sub>, ..., _x_<sub>N</sub>]_ bo'lsin. _i_-chi token uchun ehtimollik, _p_<sub>i</sub>, quyidagicha hisoblanadi:

``` js
pᵢ = softmax(xᵢ) = eˣᵢ / (Σⱼ eˣⱼ)
```

## _Sampling_ strategiyalari

To'g'ri _sampling_ strategiyasi modelni sizning dasturingizga mosroq javoblar generatsiya qilishga undashi mumkin. Masalan, bir _sampling_ strategiyasi modelni ijodiyroq javoblar generatsiya qilishga majbur qilsa, boshqasi uning generatsiyalarini bashorat qilinadiganroq qilishi mumkin. Modellarni ma'lum xususiyatlarga ega javoblar tomon "yo'naltirish" uchun ko'plab turli _sampling_ strategiyalari taqdim etilgan. Siz o'zingizning _sampling_ strategiyangizni ham ishlab chiqishingiz mumkin, garchi bu odatda modelning _logit_'lariga kirishni talab qilsa ham. Keling, ularning qanday ishlashini ko'rish uchun bir nechta keng tarqalgan _sampling_ strategiyalarini ko'rib chiqamiz.

### Harorat (`Temperature`)

Keyingi tokenni ehtimollik taqsimotiga ko'ra _sampling_ qilishning bir muammosi shundaki, model kamroq ijodkor (`creative`) bo'lishi mumkin. Oldingi misolda, "qizil", "yashil", "binafsha" kabi keng tarqalgan ranglar eng yuqori ehtimolliklarga ega. Til modelining javobi besh yoshli bolanikiga o'xshab qoladi: "Mening sevimli rangim yashil". "The" (inglizcha artikl) kabi so'zlarning ehtimoli past bo'lgani uchun, modelning "Mening sevimli rangim — bahor tongida sokin ko'lning rangi" kabi ijodiy jumla generatsiya qilish ehtimoli past bo'ladi.

Mumkin bo'lgan qiymatlarning ehtimolliklarini qayta taqsimlash uchun siz harorat (`temperature`) bilan _sampling_ qilishingiz mumkin. Intuitiv ravishda, yuqori harorat keng tarqalgan tokenlarning ehtimolliklarini pasaytiradi va natijada kamroq uchraydigan tokenlarning ehtimolliklarini oshiradi. Bu modellarga ijodiyroq javoblar yaratish imkonini beradi.

Harorat — bu `softmax` transformatsiyasidan oldin _logit_'larni sozlash uchun ishlatiladigan doimiy qiymat. _Logit_'lar haroratga bo'linadi. Berilgan _T_ harorati uchun, _i_-chi token uchun sozlangan _logit_ `xᵢ / T` bo'ladi. Keyin `softmax` xᵢ o'rniga ushbu sozlangan _logit_'ga qo'llaniladi.


Haroratning ehtimolliklarga ta'sirini o'rganish uchun oddiy bir misolni ko'rib chiqamiz. Tasavvur qiling, bizda faqat ikkita ehtimoliy natijaga ega bo'lgan model bor: A va B. Oxirgi qatlamdan hisoblangan _logit_'lar [1, 2]. A uchun _logit_ 1, B uchun esa 2.

- **Haroratsiz** (bu 1 ga teng haroratni ishlatish bilan bir xil), `softmax` ehtimolliklari [0.27, 0.73] bo'ladi. Model 73% hollarda B ni tanlaydi.
- **Harorat = 0.5** bo'lganda, ehtimolliklar [0.12, 0.88] bo'ladi. Endi model 88% hollarda B ni tanlaydi.

Harorat qanchalik yuqori bo'lsa, modelning eng yaqqol qiymatni (eng yuqori _logit_'ga ega qiymatni) tanlash ehtimoli shunchalik past bo'ladi, bu esa model natijalarini ijodiyroq, lekin potensial ravishda kamroq izchil qiladi. Harorat qanchalik past bo'lsa, modelning eng yaqqol qiymatni tanlash ehtimoli shunchalik yuqori bo'ladi, bu esa model natijasini izchilroq, lekin potensial ravishda zerikarliroq qiladi.[^24]

2-16-rasmda turli haroratlarda A va B tokenlari uchun `softmax` ehtimolliklari ko'rsatilgan. Harorat 0 ga yaqinlashgan sari, modelning B tokenini tanlash ehtimoli 1 ga yaqinlashadi. Bizning misolimizda, 0.1 dan past harorat uchun model deyarli har doim B ni chiqaradi. Harorat oshgan sari, A tokenining tanlanish ehtimoli ortadi, B tokenining tanlanish ehtimoli esa kamayadi. Model provayderlari odatda haroratni 0 va 2 oralig'ida cheklashadi. Agar siz o'z modelingizga ega bo'lsangiz, istalgan manfiy bo'lmagan haroratdan foydalanishingiz mumkin. Ijodiy qo'llanish holatlari uchun ko'pincha 0.7 harorat tavsiya etiladi, chunki u ijodkorlik va bashorat qilinuvchanlik o'rtasidagi muvozanatni ta'minlaydi, lekin siz tajriba o'tkazib, o'zingiz uchun eng yaxshi ishlaydigan haroratni topishingiz mumkin.

![2-16-rasm. A va B tokenlarining logitlari [1, 2] bo'lganda, turli haroratlardagi softmax ehtimolliklari.](/ai-engineering/2-chapter/2.16-figure.png)

<div className='text-center text-sm italic'>2-16-rasm. A va B tokenlarining _logit_'lari [1, 2] bo'lganda, turli haroratlardagi `softmax` ehtimolliklari. Harorat qiymatini belgilamasdan, ya'ni 1 ga teng haroratdan foydalanganda, B ning `softmax` ehtimoli 73% bo'lardi.</div>

Model natijalari izchilroq bo'lishi uchun haroratni 0 ga o'rnatish keng tarqalgan amaliyotdir. Texnik jihatdan, harorat hech qachon 0 bo'la olmaydi — _logit_'larni 0 ga bo'lish mumkin emas. Amalda esa, biz haroratni 0 ga o'rnatganimizda, model shunchaki _logit_ sozlamasi va `softmax` hisob-kitobini qilmasdan, eng katta _logit_'ga ega bo'lgan tokenni tanlaydi.[^25]

> **Maslahat** <br/>
> SI modeli bilan ishlashdagi keng tarqalgan nosozliklarni tuzatish (`debugging`) usullaridan biri — bu modelning berilgan kirish ma'lumotlari uchun hisoblagan ehtimolliklariga qarashdir. Masalan, agar ehtimolliklar tasodifiy ko'rinsa, demak, model hali ko'p narsa o'rganmagan.

Ko'pgina model provayderlari o'z modellari tomonidan generatsiya qilingan ehtimolliklarni [_logprobs_](https://cookbook.openai.com/examples/using_logprobs) sifatida qaytaradi. _Logprobs_, ya'ni logarifmik ehtimolliklar (`log probabilities`), logarifmik shkaladagi ehtimolliklardir. Neyron to'rning ehtimolliklari bilan ishlaganda logarifmik shkalaga afzallik beriladi, chunki u [`underflow`](https://en.wikipedia.org/wiki/Arithmetic_underflow) muammosini kamaytirishga yordam beradi.[^26] Til modeli 100 000 hajmli lug'at bilan ishlayotgan bo'lishi mumkin, bu esa ko'plab tokenlar uchun ehtimolliklar mashina tomonidan ifodalash uchun juda kichik bo'lishi mumkinligini anglatadi. Kichik sonlar 0 ga yaxlitlanishi mumkin. Logarifmik shkala bu muammoni kamaytirishga yordam beradi.

2-17-rasmda _logit_'lar, ehtimolliklar va _logprob_'larning qanday hisoblanishi ish jarayoni ko'rsatilgan.

![2-17-rasm. Logitlar, ehtimolliklar va logprobs'larning qanday hisoblanishi.](/ai-engineering/2-chapter/2.17-figure.png)

<div className='text-center text-sm italic'>2-17-rasm. _Logit_'lar, ehtimolliklar va _logprob_'larning qanday hisoblanishi.</div>

Kitob davomida ko'rib turganingizdek, _logprob_ dasturlarni yaratish (ayniqsa, tasniflash uchun), dasturlarni baholash va modellarning ichki ishlashini tushunish uchun foydalidir. Biroq, ushbu kitob yozilayotgan vaqtda, ko'plab model provayderlari o'z modellarining _logprob_'larini oshkor qilmaydi, yoki agar oshkor qilsalar ham, _logprob_ _API_'si cheklangan bo'ladi.[^27] Cheklangan _logprob_ _API_'si, ehtimol, xavfsizlik sabablari bilan bog'liq, chunki modelning oshkor qilingan _logprob_'lari boshqalarga modelni nusxalashni osonlashtiradi.

### `Top-k`

`Top-k` — bu model javoblarining xilma-xilligini haddan tashqari yo'qotmasdan, hisoblash yukini kamaytirish uchun mo'ljallangan _sampling_ strategiyasidir. Esingizda bo'lsa, `softmax` qatlami barcha mumkin bo'lgan qiymatlar bo'yicha ehtimollik taqsimotini hisoblash uchun ishlatilardi. `Softmax` barcha mumkin bo'lgan qiymatlar ustidan ikki marta o'tishni talab qiladi: biri `Σⱼeˣʲ` eksponensial yig'indini bajarish uchun va biri har bir qiymat uchun `eˣⁱ / (Σⱼeˣʲ)` ni bajarish uchun. Katta lug'atga ega bo'lgan til modeli uchun bu jarayon hisoblash jihatidan qimmatga tushadi.

Bu muammoni chetlab o'tish uchun, model _logit_'larni hisoblab bo'lgach, biz eng yuqori **k** ta _logit_'ni tanlab olamiz va `softmax`'ni faqat shu eng yuqori **k** ta _logit_ ustida bajaramiz. Dasturingiz qanchalik xilma-xil bo'lishini xohlayotganingizga qarab, **k** qiymati 50 dan 500 gacha bo'lishi mumkin — bu modelning lug'at hajmidan ancha kichikdir. Keyin model shu eng yuqori qiymatlar orasidan _sampling_ qiladi. Kichikroq **k** qiymati matnni bashorat qilinadiganroq, lekin kamroq qiziqarli qiladi, chunki model ehtimoliy so'zlarning kichikroq to'plami bilan cheklanib qoladi.

### `Top-p`

`Top-k` _sampling_'ida ko'rib chiqiladigan qiymatlar soni **k** ga qat'iy belgilangan. Biroq, bu son vaziyatga qarab o'zgarishi kerak. Masalan, "Musiqani yoqtirasizmi? Faqat ha yoki yo'q deb javob bering." prompti berilganda, ko'rib chiqiladigan qiymatlar soni ikkita bo'lishi kerak: ha va yo'q. "Hayotning ma'nosi nima?" prompti berilganda esa, ko'rib chiqiladigan qiymatlar soni ancha kattaroq bo'lishi kerak.

`Top-p`, shuningdek, yadroviy _sampling_ (`nucleus sampling`) deb ham ataladi, _sampling_ uchun qiymatlarni yanada dinamikroq tanlash imkonini beradi. `Top-p` _sampling_'ida model eng ehtimoliy keyingi qiymatlarning ehtimolliklarini kamayish tartibida yig'ib boradi va yig'indi **p** ga yetganda to'xtaydi. Faqat shu yig'ma ehtimollik ichidagi qiymatlar ko'rib chiqiladi. Til modellarida `top-p` (yadroviy) _sampling_ uchun keng tarqalgan qiymatlar odatda 0.9 dan 0.95 gacha bo'ladi. Masalan, `top-p` qiymatining 0.9 bo'lishi, model yig'ma ehtimolligi 90% dan oshadigan eng kichik qiymatlar to'plamini ko'rib chiqishini anglatadi.

Aytaylik, barcha tokenlarning ehtimolliklari 2-18-rasmda ko'rsatilganidek. Agar `top-p` 90% bo'lsa, faqat "ha" va "balki" ko'rib chiqiladi, chunki ularning yig'ma ehtimolligi 90% dan katta. Agar `top-p` 99% bo'lsa, unda "ha", "balki" va "yo'q" ko'rib chiqiladi.

![2-18-rasm. Token ehtimolliklariga misol.](/ai-engineering/2-chapter/2.18-figure.png)

<div className='text-center text-sm italic'>2-18-rasm. Token ehtimolliklariga misol.</div>

`Top-k`'dan farqli o'laroq, `top-p` `softmax` hisoblash xarajatlarini har doim ham kamaytirmaydi. Uning afzalligi shundaki, u har bir kontekst uchun faqat eng munosib qiymatlar to'plamiga e'tibor qaratgani sababli, natijalarning kontekstga yanada mosroq bo'lishiga imkon beradi. Nazariy jihatdan, `top-p` _sampling_'ining jiddiy ustunliklari yo'qdek tuyuladi. Biroq, amalda, `top-p` _sampling_'i o'zini a'lo darajada namoyon etdi, bu esa uning keng ommalashishiga sabab bo'ldi.

Bunga bog'liq bo'lgan yana bir _sampling_ strategiyasi bu `min-p` bo'lib, unda siz _sampling_ jarayonida ko'rib chiqilishi uchun token erishishi kerak bo'lgan minimal ehtimollikni belgilaysiz.

### To'xtatish shartlari

Avtoregressiv til modeli tokenlar ketma-ketligini birin-ketin generatsiya qilish orqali yaratadi. Uzun natija ko'proq vaqt sarflaydi, ko'proq hisoblash quvvati (ya'ni, pul)[^28] talab qiladi va ba'zan foydalanuvchilarning g'ashiga tegishi mumkin. Shu sababli, model uchun generatsiyani yakunlash shartini belgilash maqsadga muvofiq.

Eng oson usullardan biri — bu modeldan belgilangan miqdordagi tokenlardan so'ng generatsiyani to'xtatishni so'rashdir. Buning kamchiligi shundaki, natija katta ehtimol bilan gapning o'rtasida uzilib qoladi. Yana bir usul — bu to'xtash tokenlari (`stop tokens`) yoki to'xtash so'zlaridan (`stop words`) foydalanish. Masalan, siz modeldan ketma-ketlikning tugash tokenini (`end-of-sequence token`) uchratganda generatsiyani to'xtatishni so'rashingiz mumkin. To'xtatish shartlari kechikish (_latency_) va xarajatlarni kamaytirishda ancha qo'l keladi.

Vaqtidan oldin to'xtatishning salbiy tomoni shundaki, agar siz modellardan ma'lum bir formatdagi natijalarni generatsiya qilishni xohlasangiz, muddatidan oldin to'xtash natijalarning noto'g'ri formatlanishiga (`malformatted`) olib kelishi mumkin. Masalan, agar siz modeldan _JSON_ generatsiya qilishni so'rasangiz, vaqtidan oldin to'xtash natijaviy _JSON_'da yopuvchi qavslar kabi elementlarning tushib qolishiga sabab bo'lishi mumkin, bu esa generatsiya qilingan _JSON_'ni tahlil qilishni (`parsing`) qiyinlashtiradi.

## _Inference_ bosqichida kengaytirilgan hisoblash

Oldingi bo'limda model keyingi tokenni qanday _sampling_ qilishi mumkinligi muhokama qilindi. Ushbu bo'limda esa model butun natijani qanday _sampling_ qilishi mumkinligi muhokama qilinadi.

Model javobining sifatini oshirishning oddiy usullaridan biri bu **_inference_ bosqichida kengaytirilgan hisoblash** (`test time compute`) strategiyasidir: har bir so'rov uchun faqat bitta javob generatsiya qilish o'rniga, siz yaxshi javoblar ehtimolini oshirish uchun bir nechta javob generatsiya qilasiz. _Inference_ bosqichida kengaytirilgan hisoblashni amalga oshirishning bir usuli — bu ushbu bobda avvalroq muhokama qilingan "N tadan eng yaxshisi" (`best of N`) texnikasidir — siz tasodifiy ravishda bir nechta natija generatsiya qilasiz va eng yaxshi ishlaydiganini tanlaysiz. Biroq, bir nechta natijani qanday generatsiya qilish borasida strategikroq yondashishingiz ham mumkin. Masalan, barcha natijalarni mustaqil ravishda generatsiya qilish o'rniga (bu ko'plab kamroq istiqbolli nomzodlarni o'z ichiga olishi mumkin), siz ketma-ketlik generatsiyasining har bir qadamida belgilangan miqdordagi eng istiqbolli nomzodlarni (nur yoki `beam`) generatsiya qilish uchun nurli qidiruvdan ([`beam search`](https://en.wikipedia.org/wiki/Beam_search)) foydalanishingiz mumkin.

_Inference_ bosqichida kengaytirilgan hisoblash samaradorligini oshirishning oddiy strategiyasi — bu natijalarning xilma-xilligini oshirishdir, chunki xilma-xilroq variantlar to'plami yaxshiroq nomzodlarni berishi ehtimoli yuqoriroq. Agar siz turli xil variantlarni generatsiya qilish uchun bir xil modeldan foydalansangiz, uning natijalarini xilma-xillashtirish uchun modelning _sampling_ parametrlarini o'zgartirib turish ko'pincha yaxshi amaliyotdir.

Garchi siz odatda bir nechta natijani _sampling_ qilish orqali model samaradorligida biroz yaxshilanishni kutishingiz mumkin bo'lsa-da, bu qimmatga tushadi. O'rtacha hisobda, ikkita natija generatsiya qilish bitta natija generatsiya qilishdan taxminan ikki baravar qimmatroqqa tushadi.[^29]

<Callout>
#### Ogohlantirish

Men mavjud adabiyotlarga mos kelish uchun **_inference_ bosqichida kengaytirilgan hisoblash** (`test time compute`) atamasini ishlataman, garchi bir nechta dastlabki taqrizchilar bu atama chalg'ituvchi ekanligiga e'tiroz bildirishgan bo'lsa ham. SI tadqiqotlarida "sinov vaqti" (`test time`) odatda _inference_'ni anglatadi, chunki tadqiqotchilar asosan faqat modelni sinash uchun _inference_ qilishadi. Biroq, bu texnikani umuman olganda amaliyotdagi modellarga ham qo'llash mumkin. U **_inference_ bosqichida kengaytirilgan hisoblash** deb ataladi, chunki siz _sampling_ qilishingiz mumkin bo'lgan natijalar soni har bir _inference_ chaqiruviga qancha hisoblash quvvati ajrata olishingiz bilan belgilanadi.
</Callout>

Eng yaxshi natijani tanlash uchun, siz foydalanuvchilarga bir nechta natijani ko'rsatib, ularga o'zlari uchun eng yaxshi ishlaydiganini tanlash imkonini berishingiz yoki eng yaxshisini tanlash usulini ishlab chiqishingiz mumkin. Tanlash usullaridan biri — bu eng yuqori ehtimollikka ega bo'lgan natijani tanlashdir. Til modelining natijasi — bu tokenlar ketma-ketligi va har bir token model tomonidan hisoblangan ehtimollikka ega. Natijaning ehtimolligi — bu natijadagi barcha tokenlar ehtimolliklarining ko'paytmasidir.

["I", "love", "food"] tokenlar ketma-ketligini ko'rib chiqaylik. Agar "I" uchun ehtimollik 0.2, "I" berilganda "love" uchun ehtimollik 0.1 va "I" va "love" berilganda "food" uchun ehtimollik 0.3 bo'lsa, ketma-ketlikning ehtimolligi: `0.2 × 0.1 × 0.3 = 0.006` bo'ladi. Matematik jihatdan buni quyidagicha ifodalash mumkin:

``` md
p(I love food) = p(I) × p(I | love) × p(food | I, love)
```

Esingizda bo'lsa, ehtimolliklar bilan logarifmik shkalada ishlash osonroq. Ko'paytmaning logarifmi logarifmlar yig'indisiga teng, shuning uchun tokenlar ketma-ketligining _logprob_'i ketma-ketlikdagi barcha tokenlar _logprob_'larining yig'indisiga teng:

``` md
logprob(I love food) = logprob(I) + logprob(I | love) + logprob(food | I, love)
```

Qo'shishda, uzunroq ketma-ketliklar umumiy _logprob_'i pastroq bo'lishi ehtimoli yuqori (chunki _logprob_ qiymatlari odatda manfiy bo'ladi, chunki 0 va 1 orasidagi qiymatlarning logarifmi manfiydir). Qisqa ketma-ketliklarga moyillikni oldini olish uchun, siz ketma-ketlik yig'indisini uning uzunligiga bo'lish orqali o'rtacha _logprob_'dan foydalanishingiz mumkin. Bir nechta natijani _sampling_ qilganingizdan so'ng, siz eng yuqori o'rtacha _logprob_'ga ega bo'lganini tanlaysiz. Ushbu kitob yozilayotgan vaqtda, "OpenAI" _API_'si aynan shu usuldan foydalanadi.[^30]

### Tanlov uchun mukofot modellaridan foydalanish

Yana bir tanlov usuli — bu oldingi bo'limda muhokama qilinganidek, har bir natijani baholash uchun mukofot modelidan (`reward model`) foydalanishdir. Esingizda bo'lsa, ["Stitch Fix"](https://multithreaded.stitchfix.com/blog/2023/03/06/expert-in-the-loop-generative-ai-at-stitch-fix/) ham, ["Grab"](https://engineering.grab.com/llm-powered-data-classification) ham o'zlarining mukofot modellari yoki verifikatorlari (`verifiers`) tomonidan yuqori ball berilgan natijalarni tanlashadi. ["Nextdoor"](https://engblog.nextdoor.com/let-ai-entertain-you-increasing-user-engagement-with-generative-ai-and-rejection-sampling-50a402264f56?gi=f36ef5807864) mukofot modelidan foydalanish ularning dasturi samaradorligini oshirishda asosiy omil bo'lganini aniqladi (2023).

"OpenAI" ham o'z modellariga matematik masalalarning eng yaxshi yechimlarini tanlashda yordam berish uchun verifikatorlarni o'qitgan ([Cobbe va boshq., 2021](https://arxiv.org/pdf/2110.14168)). Ular verifikatordan foydalanish model samaradorligini sezilarli darajada oshirganini aniqladilar. Aslida, verifikatorlardan foydalanish model hajmini 30 baravar oshirish bilan deyarli bir xil samaradorlik o'sishiga olib kelgan. Bu shuni anglatadiki, verifikatordan foydalanadigan 100 million parametrli model verifikatordan foydalanmaydigan 3 milliard parametrli model bilan bir xil darajada ishlay oladi.

"DeepMind" _inference_ bosqichida kengaytirilgan hisoblashning (`test time compute`) qiymatini yanada isbotlab, _inference_ bosqichida kengaytirilgan hisoblashni miqyoslash (masalan, _inference_ paytida ko'proq natija generatsiya qilish uchun ko'proq hisoblash quvvati ajratish) model parametrlarini miqyoslashdan ko'ra samaraliroq bo'lishi mumkinligini ta'kidlaydi ([Snell va boshq., 2024](https://arxiv.org/abs/2408.03314)). Xuddi shu maqolada qiziqarli bir savol o'rtaga tashlanadi: Agar _LLM_'ga qat'iy belgilangan, ammo sezilarli miqdordagi _inference_ vaqti hisoblash quvvatidan foydalanishga ruxsat berilsa, u qiyin bir prompt bo'yicha o'z samaradorligini qanchalik oshira oladi?

"OpenAI" tajribasida ko'proq natijalarni _sampling_ qilish yaxshiroq samaradorlikka olib keldi, ammo faqat ma'lum bir nuqtagacha. Bu tajribada o'sha nuqta 400 ta natija edi. Bu nuqtadan o'tgach, samaradorlik pasayadi (2-19-rasm). Ular _sampling_ qilingan natijalar soni ortgan sari, verifikatorni aldashi mumkin bo'lgan zararli (`adversarial`) natijalarni topish ehtimoli ham ortadi, deb taxmin qilishdi. Biroq, Stenford tajribasi boshqa bir xulosani ko'rsatdi. “Monkey Business” ([Brown va boshq., 2024](https://scalingintelligence.stanford.edu/blogs/monkeys/)) tadqiqoti shuni ko'rsatadiki, namunalar soni 1 dan 10 000 gacha ortgan sari yechilgan masalalar soni ko'pincha log-chiziqli ravishda ortadi. Garchi _inference_ bosqichida kengaytirilgan hisoblashni cheksiz miqyoslash mumkinmi yoki yo'qligi haqida o'ylash qiziqarli bo'lsa-da, menimcha, amaliyotda hech kim har bir kirish uchun 400 yoki 10 000 xil natijani _sampling_ qilmaydi. Xarajatlar juda katta bo'lib ketardi.

![2-19-rasm. "OpenAI" (2021) ko'proq natijalarni sampling qilish yaxshiroq samaradorlikka olib kelishini, lekin bu faqat 400 ta natijagacha ishlashini aniqladi.](/ai-engineering/2-chapter/2.19-figure.png)

<div className='text-center text-sm italic'>2-19-rasm. ["OpenAI"](https://arxiv.org/abs/2110.14168) (2021) ko'proq natijalarni _sampling_ qilish yaxshiroq samaradorlikka olib kelishini, lekin bu faqat 400 ta natijagacha ishlashini aniqladi.</div>

Siz, shuningdek, eng yaxshi javobni tanlash uchun dasturga xos evristik usullardan foydalanishingiz mumkin. Masalan, agar dasturingiz qisqaroq javoblardan foyda ko'rsa, siz eng qisqa nomzodni tanlashingiz mumkin. Agar dasturingiz tabiiy tilni _SQL_ so'rovlariga o'girsa, siz modeldan to'g'ri _SQL_ so'rovini generatsiya qilmaguncha natijalar generatsiya qilishda davom etishini so'rashingiz mumkin.

_Inference_ bosqichida kengaytirilgan hisoblashning ayniqsa qiziqarli bir qo'llanilishi — bu kechikish (_latency_) muammosini yengib o'tishdir. Ba'zi so'rovlar uchun, ayniqsa, fikrlar zanjiri (`chain-of-thought`) so'rovlari uchun, model javobni yakunlash uchun uzoq vaqt sarflashi mumkin. "TIFIN" kompaniyasining SI rahbari Kittipat Kampa menga aytishicha, uning jamoasi o'z modelidan bir nechta javobni parallel ravishda generatsiya qilishni so'raydi va foydalanuvchiga birinchi bo'lib yakunlangan va to'g'ri bo'lgan javobni ko'rsatadi.

### Ko'pchilik ovozi bilan tanlash

Bir nechta natijalar to'plami orasidan eng ko'p uchragan natijani tanlash, ayniqsa, aniq javoblar kutiladigan vazifalar uchun foydali bo'lishi mumkin.[^31] Masalan, matematik masala berilganda, model uni bir necha marta yechishi va eng ko'p uchragan javobni o'zining yakuniy yechimi sifatida tanlashi mumkin. Xuddi shunday, ko'p tanlovli savol uchun model eng ko'p uchragan javob variantini tanlashi mumkin. "Google" `Gemini`'ni _MMLU_ benchmarkida baholaganda aynan shunday qilgan. Ular har bir savol uchun 32 ta natijani _sampling_ qilishgan. Bu modelga har bir savol uchun faqat bitta natija bilan erishishi mumkin bo'lganidan yuqoriroq ball olish imkonini bergan.

Agar model kirishdagi kichik o'zgarishlarga o'z natijalarini keskin o'zgartirmasa, u **mustahkam** (`robust`) hisoblanadi. Model qanchalik mo'rt (`less robust`) bo'lsa, siz bir nechta natijani _sampling_ qilishdan shunchalik ko'p foyda ko'rasiz.[^32] Bir loyihada biz mahsulot tasviridan ma'lum bir ma'lumotni ajratib olish uchun SI'dan foydalandik. Biz shuni aniqladikki, bir xil tasvir uchun modelimiz ma'lumotni faqat yarim hollarda o'qiy oldi. Qolgan yarim hollarda esa, model tasvir juda xira yoki matn o'qish uchun juda kichik ekanligini aytdi. Biroq, har bir tasvir bilan uch marta urinib ko'rish orqali, model aksariyat tasvirlar uchun to'g'ri ma'lumotni ajratib olishga muvaffaq bo'ldi.

## Strukturalashgan natijalar

Amaliyotda ko'pincha modellardan ma'lum formatlarga rioya qiladigan natijalarni generatsiya qilish talab etiladi. Strukturalashgan natijalar (`Structured outputs`) quyidagi ikki holat uchun juda muhimdir:

#### 1. Strukturalashgan natijalarni talab qiladigan vazifalar

Bu holatdagi eng keng tarqalgan vazifalar toifasi — bu semantik tahlildir (`semantic parsing`). Semantik tahlil tabiiy tilni strukturalashgan, mashina o'qiy oladigan formatga o'tkazishni o'z ichiga oladi. Matndan-_SQL_'ga (`Text-to-SQL`) — bu semantik tahlilning bir misoli bo'lib, unda natijalar to'g'ri _SQL_ so'rovlari bo'lishi shart. Semantik tahlil foydalanuvchilarga _API_'lar bilan tabiiy til (masalan, ingliz tili) yordamida ishlash imkonini beradi. Masalan, matndan-`PostgreSQL`'ga o'girish foydalanuvchilarga `PostgreSQL`'da yozish o'rniga, "So'nggi 6 oy ichidagi o'rtacha oylik daromad qancha" kabi inglizcha so'rovlar yordamida `Postgres` ma'lumotlar bazasidan so'rov qilish imkonini beradi.

Quyida `GPT-4o`'ga matndan-_regex_'ga o'girish vazifasini bajarish uchun berilgan promptga misol keltirilgan. Natijalar `GPT-4o` tomonidan generatsiya qilingan haqiqiy natijalardir:

``` mdx
Tizim prompti:
`Biror element berilganda, bu element yozilishi mumkin bo'lgan barcha usullarni ifodalovchi regex yarating. Faqat regex'ni qaytaring.`

Misol:
"AQSH telefon raqami -> \+?1?\s?(\()?(\d{3})(?(1)\))[-.\s]?(\d{3})[-.\s]?(\d{4})`

Foydalanuvchi prompti:
`Elektron pochta manzili ->`

GPT-4o:
`[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}`

Foydalanuvchi prompti:
`Sanalar ->`

GPT-4o:
`(?:\d{1,2}[\/\-\.])(?:\d{1,2}[\/\-\.])?\d{2,4}`
```

Bu holatdagi boshqa vazifalar toifalariga tasniflash kiradi, bunda natijalar to'g'ri sinflar bo'lishi shart.

#### 2. Natijalari keyingi dasturlar tomonidan ishlatiladigan vazifalar

Bu holatda, vazifaning o'zi natijalarning strukturalashgan bo'lishini talab qilmaydi, lekin natijalar boshqa dasturlar tomonidan ishlatilgani uchun, ular o'sha dasturlar tomonidan tahlil qilinadigan (`parsable`) bo'lishi kerak.
Masalan, agar siz elektron pochta yozish uchun SI modelidan foydalansangiz, xatning o'zi strukturalashgan bo'lishi shart emas. Biroq, ushbu xatdan foydalanadigan keyingi dastur uning ma'lum bir formatda bo'lishini talab qilishi mumkin — masalan, `{"title": [SARLAVHA], "body": [XAT MATNI]}` kabi maxsus kalitlarga ega bo'lgan _JSON_ hujjati.
Bu, ayniqsa, 6-bobda muhokama qilinadigan agentlik ish jarayonlari (`agentic workflows`) uchun muhim, chunki ularda modelning natijalari ko'pincha model ishlatishi mumkin bo'lgan vositalarga kirish ma'lumoti sifatida uzatiladi.

### Strukturalashgan natijalarni ta'minlash

Strukturalashgan natijalarni qo'llab-quvvatlaydigan freymvorklarga [`guidance`](https://github.com/guidance-ai/guidance), [`outlines`](https://github.com/dottxt-ai/outlines), [`instructor`](https://github.com/567-labs/instructor) va [`llama.cpp`](https://github.com/ggml-org/llama.cpp/discussions/177) kiradi. Har bir model provayderi ham o'z modellarining strukturalashgan natijalarni generatsiya qilish qobiliyatini yaxshilash uchun o'z texnikalaridan foydalanishi mumkin. "OpenAI" o'zining matn generatsiyasi _API_'sida [_JSON_ rejimini](https://platform.openai.com/docs/guides/structured-outputs#json-mode) joriy etgan birinchi model provayderi bo'ldi. Shuni unutmangki, _API_'ning _JSON_ rejimi odatda faqat natijalarning to'g'ri _JSON_ ekanligini kafolatlaydi — _JSON_ obyektlarining mazmunini emas. Aks holda to'g'ri bo'lgan generatsiya qilingan _JSON_'lar ham, agar generatsiya juda erta to'xtasa, masalan, maksimal chiqish tokeni uzunligiga yetganda, uzilib qolishi va shu sababli tahlil qilib bo'lmaydigan (`not parsable`) bo'lishi mumkin. Biroq, agar maksimal token uzunligi juda uzun qilib belgilansa, modelning javoblari ham juda sekin, ham qimmat bo'lib qoladi.

2-20-rasmda `guidance`'dan foydalanib, natijalarni ma'lum bir variantlar to'plami va _regex_ bilan cheklangan holda generatsiya qilishning ikkita misoli ko'rsatilgan.

![2-20-rasm. Cheklangan natijalarni generatsiya qilish uchun guidance'dan foydalanish.](/ai-engineering/2-chapter/2.20-figure.png)

<div className='text-center text-sm italic'>2-20-rasm. Cheklangan natijalarni generatsiya qilish uchun `guidance`'dan foydalanish.</div>

### Strukturalashgan natijalarga erishish yondashuvlari

Siz modelni SI stekining turli qatlamlarida strukturalashgan natijalarni generatsiya qilishga yo'naltirishingiz mumkin: _prompting_, keyingi ishlov berish (`post-processing`), _inference_ bosqichida kengaytirilgan hisoblash (`test time compute`), cheklangan _sampling_ (`constrained sampling`) va _finetuning_. Dastlabki uchtasi ko'proq "bog'lam"ga o'xshaydi. Ular model allaqachon strukturalashgan natijalarni generatsiya qilishda ancha yaxshi bo'lsa va shunchaki kichik bir turtkiga muhtoj bo'lsa, eng yaxshi holatda ishlaydi. Jiddiyroq "muolaja" uchun esa sizga cheklangan _sampling_ va _finetuning_ kerak bo'ladi.

_Inference_ bosqichida kengaytirilgan hisoblash avvalgi bo'limda muhokama qilindi — kutilgan formatga mos keladigan natija topilmaguncha generatsiya qilishda davom etish. Ushbu bo'lim qolgan to'rtta yondashuvga e'tibor qaratadi.

### _Prompting_

**Prompt orqali yo'naltirish** — bu strukturalashgan natijalarga erishish yo'lidagi birinchi qadamdir. Siz modelga istalgan formatda natija generatsiya qilish bo'yicha ko'rsatma berishingiz mumkin. Biroq, modelning bu ko'rsatmaga amal qila olishi uning ko'rsatmalarga amal qilish qobiliyatiga (4-bobda muhokama qilinadi) va ko'rsatmaning aniqligiga (5-bobda muhokama qilinadi) bog'liq. Garchi modellar ko'rsatmalarga amal qilishda tobora yaxshilanib borayotgan bo'lsa-da, ularning har doim ham ko'rsatmalaringizga rioya qilishiga kafolat yo'q.[^33] Hatto bir necha foizlik noto'g'ri natijalar ham ko'plab dasturlar uchun qabul qilib bo'lmas holat bo'lishi mumkin.

To'g'ri natijalar foizini oshirish uchun, ba'zilar dastlabki _prompt_ natijasini tekshirish va/yoki tuzatish uchun SI'dan foydalanadilar. Bu 3-bobda muhokama qilingan "SI — hakam" yondashuvining bir namunasidir. Bu shuni anglatadiki, har bir natija uchun kamida ikkita model so'rovi bo'ladi: biri natijani generatsiya qilish uchun va biri uni tekshirish uchun. Garchi qo'shimcha tekshiruv qatlami natijalarning to'g'riligini sezilarli darajada yaxshilashi mumkin bo'lsa-da, qo'shimcha tekshiruv so'rovlari keltirib chiqaradigan ortiqcha xarajat va kechikish (_latency_) bu yondashuvni ba'zilar uchun haddan tashqari qimmat qilib qo'yishi mumkin.

### Keyingi ishlov berish

Keyingi ishlov berish (`Post-processing`) oddiy va arzon, ammo hayratlanarli darajada yaxshi ishlashi mumkin. Dars bergan vaqtlarimda talabalar bir xil xatolarni takrorlashga moyil ekanliklarini payqaganman. Fundamental modellar bilan ishlay boshlaganimda ham xuddi shu narsani kuzatdim. Model so'rovlar bo'ylab o'xshash xatolarni takrorlashga moyil bo'ladi. Bu shuni anglatadiki, agar siz model qiladigan umumiy xatolarni topsangiz, ularni tuzatish uchun skript yozishingiz mumkin. Masalan, agar generatsiya qilingan _JSON_ obyektida yopuvchi qavs yetishmayotgan bo'lsa, o'sha qavsni qo'lda qo'shing. LinkedIn'ning himoyaviy _YAML_ parseri to'g'ri _YAML_ natijalari foizini 90% dan 99.99% gacha oshirdi ([Bottaro va Ramgopal, 2020](https://www.linkedin.com/blog/engineering/generative-ai/musings-on-building-a-generative-ai-product?_l=en_US)).

> **Maslahat:** <br/>
> _JSON_ va _YAML_ keng tarqalgan matn formatlaridir. LinkedIn ularning asosiy modeli `GPT-4` ikkalasi bilan ham ishlashini aniqladi, lekin ular o'zlarining natija formati sifatida _YAML_'ni tanladilar, chunki u kamroq yoziladigan va shuning uchun _JSON_'ga qaraganda kamroq chiqish tokenlarini talab qiladi (Bottaro va Ramgopal, 2020).

Keyingi ishlov berish faqat xatolarni tuzatish oson bo'lganda ishlaydi. Bu odatda model natijalari allaqachon asosan to'g'ri formatlangan bo'lib, vaqti-vaqti bilan kichik xatolar uchraganda sodir bo'ladi.

### Cheklangan _sampling_

Cheklangan _sampling_ (`Constrained sampling`) — bu matn generatsiyasini ma'lum bir cheklovlarga tomon yo'naltirish texnikasidir. U odatda strukturalashgan natijalar vositalari tomonidan qo'llaniladi.

Umumiy olganda, biror tokenni generatsiya qilish uchun model cheklovlarga mos keladigan qiymatlar orasidan _sampling_ qiladi. Esingizda bo'lsa, tokenni generatsiya qilish uchun modelingiz avval _logit_ vektorini chiqaradi, har bir _logit_ bitta ehtimoliy tokenga mos keladi. Cheklangan _sampling_ bu _logit_ vektorini filtrlash orqali faqat cheklovlarga mos keladigan tokenlarni saqlab qoladi. Keyin u shu to'g'ri tokenlar orasidan _sampling_ qiladi. Bu jarayon 2-21-rasmda ko'rsatilgan.

![2-21-rasm. Faqat to'g'ri natijalar orasidan sampling qilish uchun cheklovlarga mos kelmaydigan logitlarni filtrlash.](/ai-engineering/2-chapter/2.21-figure.png)

<div className='text-center text-sm italic'>2-21-rasm. Faqat to'g'ri natijalar orasidan _sampling_ qilish uchun cheklovlarga mos kelmaydigan _logit_'larni filtrlash.</div>

2-21-rasmdagi misolda cheklovni filtrlash oson. Biroq, aksariyat holatlar bunchalik oddiy emas. Sizga har bir qadamda nimaga ruxsat berilgani va nimaga ruxsat berilmaganini belgilaydigan grammatika (`grammar`) kerak bo'ladi. Masalan, _JSON_ grammatikasi `{` belgisidan keyin, agar u `{"key": "{{string}}"}` kabi satrning bir qismi bo'lmasa, yana bir `{` kelishi mumkin emasligini belgilaydi.

Bu grammatikani yaratish va uni _sampling_ jarayoniga kiritish oson ish emas. Har bir natija formati — _JSON_, _YAML_, _regex_, _CSV_ va hokazolar — o'z grammatikasini talab qilgani uchun, cheklangan _sampling_ kamroq umumlashtiriladigan (`less generalizable`) yondashuvdir. Uning qo'llanilishi tashqi vositalar yoki sizning jamoangiz tomonidan qo'llab-quvvatlanadigan grammatikali formatlar bilan cheklangan. Grammatikani tekshirish, shuningdek, generatsiya kechikishini oshirishi ham mumkin ([Brandon T. Willard, 2024](https://blog.dottxt.ai/how-fast-cfg.html)).

Ba'zilar cheklangan _sampling_'ga qarshi, chunki ular cheklangan _sampling_ uchun zarur bo'lgan resurslarni modellarni ko'rsatmalarga amal qilishda yaxshiroq bo'lishga o'rgatishga sarflash afzalroq, deb hisoblashadi.

### _Finetuning_

Modelni siz xohlagan formatga rioya qiladigan misollarda qo'shimcha sozlash (`finetuning`) — bu modellarni ushbu formatda natija generatsiya qilishga undashning eng samarali va umumiy yondashuvidir.[^34] U istalgan kutilayotgan format bilan ishlay oladi. Garchi oddiy _finetuning_ model har doim kutilgan formatni chiqarishini kafolatlamasa-da, u _prompting_'ga qaraganda ancha ishonchliroqdir.

Muayyan vazifalar uchun, siz _finetuning_'dan oldin model arxitekturasini o'zgartirish orqali natija formatini kafolatlashingiz mumkin. Masalan, tasniflash uchun, model faqat oldindan belgilangan sinflardan birini chiqarishiga ishonch hosil qilish uchun, siz fundamental model arxitekturasiga klassifikator boshi (`classifier head`) qo'shishingiz mumkin. Arxitektura 2-22-rasmdagidek ko'rinadi.[^35] Bu yondashuv, shuningdek, xususiyatlarga asoslangan transfer (`feature-based transfer`) deb ham ataladi va 7-bobda boshqa transferli o'rganish (`transfer learning`) texnikalari bilan birga batafsilroq muhokama qilinadi.

![2-22-rasm. Modelni klassifikatorga aylantirish uchun asosiy modelga klassifikator boshi qo'shish.](/ai-engineering/2-chapter/2.22-figure.png)

<div className='text-center text-sm italic'>2-22-rasm. Modelni klassifikatorga aylantirish uchun asosiy modelga klassifikator boshi qo'shish. Ushbu misolda klassifikator uchta sinf bilan ishlaydi.</div>

_Finetuning_ davomida siz butun modelni boshidan oxirigacha (`end-to-end`) yoki modelning bir qismini, masalan, ushbu klassifikator boshini qayta o'qitishingiz mumkin. Boshidan oxirigacha o'qitish ko'proq resurs talab qiladi, lekin yaxshiroq samaradorlikni va'da qiladi.

Bizga strukturalashgan natijalar uchun texnikalar kerakligining sababi — bu modelning o'zi strukturalashgan natijalarni generatsiya qilishga qodir emas degan farazdir. Biroq, modellar qudratliroq bo'lib borgani sari, ularning ko'rsatmalarga amal qilishda yaxshilanib borishini kutishimiz mumkin. Taxminimcha, kelajakda minimal _prompting_ bilan modellardan aynan bizga kerak bo'lgan narsani chiqarib olish osonlashadi va bu texnikalar kamroq ahamiyatga ega bo'lib qoladi.

## SI'ning ehtimoliy tabiati

SI modellarining o'z javoblarini _sampling_ qilish usuli ularni ehtimoliy (`probabilistic`) qiladi. Ehtimoliy bo'lish nimani anglatishini ko'rish uchun bir misolni ko'rib chiqaylik. Tasavvur qiling, siz dunyodagi eng yaxshi oshxona qaysi ekanligini bilmoqchisiz. Agar siz bu savolni do'stingizga bir daqiqa farq bilan ikki marta bersangiz, do'stingizning javoblari ikkala safar ham bir xil bo'lishi kerak. Agar siz xuddi shu savolni SI modeliga ikki marta bersangiz, uning javobi o'zgarishi mumkin. Agar SI modeli Vyetnam oshxonasi dunyodagi eng yaxshi oshxona bo'lish ehtimoli 70%, Italyan oshxonasi esa 30% deb hisoblasa, u 70% hollarda "Vyetnam oshxonasi" va 30% hollarda "Italyan oshxonasi" deb javob beradi. Ehtimoliyning aksi deterministik (`deterministic`) bo'lib, bunda natijani hech qanday tasodifiy o'zgarishlarsiz aniqlash mumkin.

Bu ehtimoliy tabiat barqarorsizlik (`inconsistency`) va gallyutsinatsiyalarga sabab bo'lishi mumkin. Barqarorsizlik — bu modelning bir xil yoki biroz farq qiladigan promptlar uchun juda farqli javoblar generatsiya qilishidir. Gallyutsinatsiya — bu modelning faktlarga asoslanmagan javob berishidir. Tasavvur qiling, internetda kimdir barcha AQSH prezidentlari o'zga sayyoraliklar ekanligi haqida esse yozgan va bu esse o'qitish ma'lumotlariga kiritilgan. Keyinchalik model ehtimoliy ravishda hozirgi AQSH prezidenti o'zga sayyoralik deb chiqaradi. AQSH prezidentlari o'zga sayyoralik ekanligiga ishonmaydigan odam nuqtai nazaridan, model buni o'zidan to'qib chiqarmoqda.

Fundamental modellar odatda juda katta hajmdagi ma'lumotlar yordamida o'qitiladi. Ular ommaviy fikrlarning yig'indisi bo'lib, o'z ichida, tom ma'noda, imkoniyatlar olamini saqlaydi. Ehtimoli noldan farqli bo'lgan har qanday narsa, qanchalik aqlga sig'mas yoki noto'g'ri bo'lmasin, SI tomonidan generatsiya qilinishi mumkin.[^36]

Bu xususiyat SI dasturlarini yaratishni ham hayajonli, ham qiyin qiladi. Ushbu kitobda ko'rib turganimizdek, SI muhandisligi sa'y-harakatlarining ko'pchiligi aynan shu ehtimoliy tabiatni jilovlash va yumshatishga qaratilgan.

Bu ehtimoliy tabiat SI'ni ijodiy vazifalar uchun ajoyib qiladi. Axir, ijodkorlik nima, agar u odatiy yo'llardan tashqariga chiqish — qolipdan tashqarida fikrlash qobiliyati bo'lmasa? SI ijodiy mutaxassislar uchun ajoyib yordamchidir. U cheksiz g'oyalar ustida izlanishi va ilgari ko'rilmagan dizaynlarni generatsiya qilishi mumkin. Biroq, xuddi shu ehtimoliy tabiat boshqa hamma narsa uchun bosh og'rig'i bo'lishi mumkin.[^37]

### Barqarorsizlik

Model barqarorsizligi (`inconsistency`) ikki holatda namoyon bo'ladi:

1.  **Bir xil kirish, har xil natija:** Modelga bir xil promptni ikki marta berish ikki xil javobga olib keladi.
2.  **Ozroq farqli kirish, keskin farqli natija:** Modelga biroz farq qiladigan prompt berish, masalan, tasodifan biror harfni katta harf bilan yozib yuborish, butunlay boshqa natijaga olib kelishi mumkin.

2-23-rasmda men `ChatGPT`'dan esselarni baholash uchun foydalanishga uringanim misoli ko'rsatilgan. Bir xil prompt uni ikki marta ishga tushirganimda menga ikki xil ball berdi: 3/5 va 5/5.

![2-23-rasm. Bir xil kirish bir xil modelda turli xil natijalarni keltirib chiqarishi mumkin.](/ai-engineering/2-chapter/2.23-figure.png)

<div className='text-center text-sm italic'>2-23-rasm. Bir xil kirish bir xil modelda turli xil natijalarni keltirib chiqarishi mumkin.</div>

Barqarorsizlik foydalanuvchi bilan ishlash qulayligini noqulayligiga sabab bo'lishi mumkin. Insonlar o'rtasidagi muloqotda biz ma'lum darajada izchillikni kutamiz. Tasavvur qiling, biror kishi har safar uchrashganingizda sizga boshqa ism aytsa. Xuddi shunday, foydalanuvchilar ham SI bilan muloqot qilganda ma'lum darajada izchillikni kutishadi.

#### Barqarorsizlikni yumshatish usullari

"Bir xil kirish, har xil natija" holati uchun barqarorsizlikni yumshatishning bir nechta yondashuvlari mavjud. Siz javobni keshlashingiz mumkin, shunda keyingi safar xuddi shu savol berilganda, o'sha javob qaytariladi. Avvalroq muhokama qilinganidek, modelning _sampling_ parametrlarini, masalan, harorat, `top-p` va `top-k` qiymatlarini qat'iy belgilashingiz mumkin. Shuningdek, `seed` o'zgaruvchisini (tasodifiy sonlar generatori uchun boshlang'ich nuqtani) ham qat'iy belgilashingiz mumkin, uni keyingi tokenni _sampling_ qilish uchun ishlatiladigan tasodifiy sonlar generatorining boshlang'ich nuqtasi deb hisoblashingiz mumkin.

Biroq, siz bu barcha o'zgaruvchilarni qat'iy belgilasangiz ham, modelingiz 100% hollarda barqaror bo'lishiga kafolat yo'q. Model natijani generatsiya qiladigan qurilma ham natijaga ta'sir qilishi mumkin, chunki turli xil mashinalar bir xil ko'rsatmani bajarishning turli usullariga ega va turli diapazondagi sonlar bilan ishlay oladi. Agar siz o'z modelingizni host qilsangiz, siz ishlatadigan qurilma ustidan biroz nazoratga ega bo'lasiz. Biroq, agar siz "OpenAI" yoki "Google" kabi model _API_ provayderidan foydalansangiz, sizga biror nazorat berish yoki bermaslik bu provayderlarga bog'liq.

Natija generatsiyasi sozlamalarini qat'iy belgilash yaxshi amaliyot, ammo bu tizimga ishonch uyg'otmaydi. Tasavvur qiling, bir o'qituvchi sizga faqat ma'lum bir xonada o'tirgandagina barqaror baho qo'ysa. Agar o'sha o'qituvchi boshqa xonada o'tirsa, uning sizga qo'yadigan baholari tartibsiz bo'lib ketadi.

Ikkinchi holat — "ozroq farqli kirish, keskin farqli natija" — ancha qiyinroq. Modelning natija generatsiyasi parametrlarini qat'iy belgilash hali ham yaxshi amaliyot, ammo bu modelni turli kirishlar uchun bir xil natijalarni generatsiya qilishga majburlamaydi. Biroq, puxta ishlab chiqilgan promptlar (5-bobda muhokama qilinadi) va xotira tizimi (6-bobda muhokama qilinadi) yordamida modellarni siz xohlagan javoblarga yaqinroq natijalar generatsiya qilishga undash mumkin.

### Gallyutsinatsiya

Gallyutsinatsiyalar faktlarga bog'liq bo'lgan vazifalar uchun halokatlidir. Agar siz SI'dan biror vaksinaning afzalliklari va kamchiliklarini tushuntirishda yordam so'rasangiz, SI'ning soxta ilmiy bo'lishini xohlamaysiz. 2023-yil iyun oyida bir advokatlik firmasi [sudga soxta huquqiy tadqiqot taqdim etgani uchun jarimaga tortildi](https://www.cbsnews.com/news/chatgpt-judge-fines-lawyers-who-used-ai/). Ular o'z ishlarini tayyorlashda `ChatGPT`'dan foydalanishgan va uning gallyutsinatsiyaga moyilligidan bexabar bo'lishgan.

Zero gallyutsinatsiya _LLM_'larning yuksalishi bilan mashhur muammoga aylangan bo'lsa-da, u "fundamental model" atamasi va Transformer arxitekturasi paydo bo'lishidan oldin ham generativ modellar uchun keng tarqalgan hodisa edi. Matn generatsiyasi kontekstida gallyutsinatsiya 2016-yildayoq tilga olingan ([Goyal va boshq., 2016](https://aclanthology.org/C16-1103/)). Gallyutsinatsiyalarni aniqlash va o'lchash o'shandan beri tabiiy til generatsiyasining (_NLG_) asosiy qismi bo'lib kelmoqda (qarang: [Lee va boshq., 2018](https://openreview.net/forum?id=SkxJ-309FQ); [Nie va boshq., 2019](https://aclanthology.org/P19-1256/); va [Zhou va boshq., 2020](https://arxiv.org/abs/2011.02593)). Ushbu bo'limda gallyutsinatsiyalar nima uchun sodir bo'lishini tushuntirishga e'tibor qaratiladi. Ularni qanday aniqlash va o'lchash esa 4-bobda muhokama qilinadi.

Agar barqarorsizlik _sampling_ jarayonidagi tasodifiylikdan kelib chiqsa, gallyutsinatsiyaning sababi ancha nozikroqdir. Faqat _sampling_ jarayonining o'zi buni yetarlicha tushuntirib bera olmaydi. Model barcha ehtimoliy variantlar orasidan natijalarni _sampling_ qiladi. Lekin ilgari hech qachon ko'rilmagan narsa qanday qilib ehtimoliy variantga aylanadi? Model o'qitish ma'lumotlarida hech qachon ko'rilmagan deb hisoblangan narsani chiqarishi mumkin. Biz buni aniq aytolmaymiz, chunki biror g'oyaning mavjudligini tekshirish uchun butun o'qitish ma'lumotlarini ko'rib chiqishning iloji yo'q. Biz endi o'zimiz tushuna olmaydigan darajada murakkab narsani yarata olish qobiliyatimiz — ham ne'mat, ham la'natdir.

#### Gallyutsinatsiya sabablari haqidagi gipotezalar

Nima uchun gallyutsinatsiyalar yuzaga kelishini tushunmasdan turib, ularni yo'q qilish yo'lini topish qiyin. Hozirda til modellari nima uchun gallyutsinatsiyaga uchrashi haqida ikkita gipoteza mavjud.

Birinchi gipoteza, dastlab "DeepMind"dagi [Ortega va boshqalar tomonidan 2021-yilda](https://arxiv.org/abs/2110.10819#deepmind) ilgari surilgan bo'lib, shundan iboratki, til modeli o'ziga berilgan ma'lumotlar va o'zi generatsiya qilgan ma'lumotlarni farqlay olmagani uchun gallyutsinatsiyaga uchraydi. Buni tasvirlash uchun bir misolni ko'rib chiqamiz.

Tasavvur qiling, siz modelga "Chip Huyen kim?" degan prompt berasiz va model generatsiya qilgan birinchi jumla: "Chip Huyen — me'mor." Model generatsiya qiladigan keyingi token "Chip Huyen kim? Chip Huyen — me'mor." ketma-ketligiga asoslanadi. Model o'zi yaratgan "Chip Huyen — me'mor." jumlasiga xuddi berilgan faktdek munosabatda bo'ladi. Odatdagidan biroz chetga chiqqan generatsiya qilingan ketma-ketlikdan boshlab, model uni kengaytirishi va mutlaqo noto'g'ri faktlarni generatsiya qilishi mumkin. Ortega va boshqa mualliflar gallyutsinatsiyalarni o'z-o'zini aldashning bir shakli deb atashgan.

2-24-rasmda `LLaVA-v1.5-7B` modelining o'z-o'zini aldashiga misol ko'rsatilgan. Men modeldan rasmdagi mahsulot yorlig'ida ko'rsatilgan tarkibini aniqlashni so'radim, bu shampun idishi edi. O'z javobida model rasmdagi mahsulot sut idishi ekanligiga o'zini ishontiradi, so'ngra mahsulot yorlig'idan olingan tarkiblar ro'yxatiga sutni qo'shishda davom etadi.

![2-24-rasm. LLaVA-v1.5-7B modelining o'z-o'zini aldashiga misol.](/ai-engineering/2-chapter/2.24-figure.png)

<div className='text-center text-sm italic'>2-24-rasm. `LLaVA-v1.5-7B` modelining o'z-o'zini aldashiga misol.</div>

Zhang va boshqalar (2023) bu hodisani **qor ko'chkisi kabi gallyutsinatsiyalar** ([`snowballing hallucinations`](https://arxiv.org/abs/2305.13534)) deb atashadi. Bir marta noto'g'ri taxmin qilgandan so'ng, model o'zining dastlabki xatosini oqlash uchun gallyutsinatsiya qilishda davom etishi mumkin. Qizig'i shundaki, mualliflar dastlabki noto'g'ri taxminlar modelning aks holda to'g'ri javob bera oladigan savollarda ham xato qilishiga sabab bo'lishi mumkinligini ko'rsatishgan (2-25-rasm).

![2-25-rasm. Dastlabki noto'g'ri taxmin modelning, hatto bu to'g'ri emasligini bilsa ham, 9677 soni 13 ga bo'linadi deb da'vo qilishiga sabab bo'lishi mumkin.](/ai-engineering/2-chapter/2.25-figure.png)

<div className='text-center text-sm italic'>2-25-rasm. Dastlabki noto'g'ri taxmin modelning, hatto bu to'g'ri emasligini bilsa ham, 9677 soni 13 ga bo'linadi deb da'vo qilishiga sabab bo'lishi mumkin.</div>

"DeepMind" maqolasi gallyutsinatsiyalarni ikkita texnika yordamida yumshatish mumkinligini ko'rsatdi. Birinchi texnika mustahkamlovchi o'rganishdan kelib chiqadi, unda model foydalanuvchi tomonidan taqdim etilgan promptlar (mustahkamlovchi o'rganishda dunyo haqidagi kuzatuvlar deb ataladi) va model tomonidan generatsiya qilingan tokenlar (modelning harakatlari deb ataladi) o'rtasidagi farqni ajratishga majbur qilinadi. Ikkinchi texnika nazoratli o'rganishga tayanadi, unda o'qitish ma'lumotlariga faktik va kontrfaktual signallar kiritiladi.

Ikkinchi gipoteza shundan iboratki, gallyutsinatsiya modelning ichki bilimlari va izohlovchining ichki bilimlari o'rtasidagi nomuvofiqlik tufayli yuzaga keladi. Bu fikrni birinchi bo'lib "OpenAI" tadqiqotchisi [Leo Gao](https://www.alignmentforum.org/posts/BgoKdAzogxmgkuuAt/behavior-cloning-is-miscalibrated) ilgari surgan. _SFT_ davomida modellar izohlovchilar tomonidan yozilgan javoblarga taqlid qilishga o'rgatiladi. Agar bu javoblar izohlovchilar ega bo'lgan, lekin model ega bo'lmagan bilimlardan foydalansa, biz aslida modelni gallyutsinatsiya qilishga o'rgatayotgan bo'lamiz. Nazariy jihatdan, agar izohlovchilar o'zlari yozgan har bir javob bilan birga ishlatgan bilimlarini ham qo'shib kiritishsa, shunda model javoblar to'qib chiqarilmaganini biladi va biz ehtimol modelni faqat o'zi bilgan narsadan foydalanishga o'rgata olamiz. Biroq, bu amalda imkonsizdir.

2023-yil aprel oyida "OpenAI" hammuassisi Jon Shulman [Berklidagi UC](https://www.youtube.com/watch?v=hhiLw5Q_UFg) ma'ruzasida xuddi shu fikrni bildirdi. Shulman, shuningdek, _LLM_'lar nimadirni bilish yoki bilmasligini o'zlari biladi, deb hisoblaydi — bu o'z-o'zidan katta da'vo. Agar bu ishonch to'g'ri bo'lsa, gallyutsinatsiyalarni modelni faqat o'zi bilgan ma'lumotlarga asoslanib javob berishga majburlash orqali tuzatish mumkin. U ikkita yechim taklif qildi. Birinchisi — verifikatsiya: har bir javob uchun modeldan ushbu javobga asos bo'lgan manbalarni topib berishni so'rash. Ikkinchisi — mustahkamlovchi o'rganishdan foydalanish. Esingizda bo'lsa, mukofot modeli faqat taqqoslashlar — A javob B javobdan yaxshiroq — yordamida o'qitiladi, nima uchun A yaxshiroq ekanligi tushuntirilmaydi. Shulmanning ta'kidlashicha, modelni biror narsani to'qib chiqargani uchun ko'proq jazolaydigan yaxshiroq mukofot funksiyasi gallyutsinatsiyalarni yumshatishga yordam berishi mumkin.

O'sha ma'ruzada Shulman "OpenAI" _RLHF_'ning gallyutsinatsiyalarni kamaytirishga yordam berishini aniqlaganini aytib o'tdi. Biroq, `InstructGPT` maqolasi _RLHF_ gallyutsinatsiyani yomonlashtirganini ko'rsatadi (2-26-rasm). Garchi _RLHF_ `InstructGPT` uchun gallyutsinatsiyalarni yomonlashtirganga o'xshasa-da, u boshqa jihatlarni yaxshiladi va umuman olganda, inson izohlovchilari faqat _SFT_ modeliga qaraganda _RLHF_ modelini afzal ko'rishdi.

![2-26-rasm. Ham RLHF, ham SFT ishlatadigan model (InstructGPT) uchun gallyutsinatsiya faqat SFT ishlatadigan xuddi shu modelga nisbatan yomonroq (Ouyang va boshq., 2022).](/ai-engineering/2-chapter/2.26-figure.png)

<div className='text-center text-sm italic'>2-26-rasm. Ham _RLHF_, ham _SFT_ ishlatadigan model (`InstructGPT`) uchun gallyutsinatsiya faqat _SFT_ ishlatadigan xuddi shu modelga nisbatan yomonroq ([Ouyang va boshq., 2022](https://arxiv.org/abs/2203.02155)).</div>

Fundamental model o'zi nimani bilishini biladi degan taxminga asoslanib, ba'zi odamlar gallyutsinatsiyani promptlar yordamida kamaytirishga harakat qilishadi, masalan, "Iloji boricha haqqoniy javob bering va agar javobga ishonchingiz komil bo'lmasa, 'Kechirasiz, men bilmayman' deb ayting" kabi qo'shimchalar bilan. Modellardan qisqa javoblar so'rash ham gallyutsinatsiyalarga yordam beradiganga o'xshaydi — model qancha kam token generatsiya qilishi kerak bo'lsa, uning biror narsani to'qib chiqarish ehtimoli shunchalik kamayadi. 5 va 6-boblardagi _prompting_ va kontekstni qurish texnikalari ham gallyutsinatsiyalarni yumshatishga yordam berishi mumkin.

Muhokama qilingan ikkita gipoteza bir-birini to'ldiradi. O'z-o'zini aldash gipotezasi o'z-o'zini nazorat qilish qanday qilib gallyutsinatsiyalarga sabab bo'lishiga e'tibor qaratsa, nomuvofiq ichki bilimlar gipotezasi nazoratli o'qitish qanday qilib gallyutsinatsiyalarga sabab bo'lishiga e'tibor qaratadi.

Agar biz gallyutsinatsiyalarni butunlay to'xtata olmasak, toki biz o'sha gallyutsinatsiyali javoblarni foydalanuvchilarga taqdim etmasakda, hech bo'lmaganda model qachon gallyutsinatsiyaga uchrayotganini aniqlay olamizmi? Xo'sh, gallyutsinatsiyalarni aniqlash ham unchalik oson emas — o'ylab ko'ring, biz uchun boshqa bir inson qachon yolg'on gapirayotganini yoki biror narsani to'qib chiqarayotganini aniqlash qanchalik qiyin. Ammo odamlar harakat qilib ko'rishgan. Biz gallyutsinatsiyalarni qanday aniqlash va o'lchashni 4-bobda muhokama qilamiz.

### Izohlar

[^24]: Harorat haqida o'ylaganimda xayolimga keladigan, unchalik ilmiy bo'lmagan vizual tasvir shuki, yuqori harorat ehtimollik taqsimotining yanada xaotik bo'lishiga olib keladi, bu esa past ehtimolli tokenlarning yuzaga chiqishiga imkon beradi.

[^25]: [`arg max`](https://en.wikipedia.org/wiki/Arg_max) funksiyasini bajarish.

[^26]: `underflow` muammosi son berilgan formatda ifodalash uchun juda kichik bo'lganda yuzaga keladi, bu esa uning nolga yaxlitlanishiga olib keladi.

[^27]: Aniqroq aytganda, ushbu kitob yozilayotgan vaqtda, "OpenAI" _API_'si sizga faqat 20 tagacha eng ehtimolli tokenlarning [_logprobs_'larini](https://platform.openai.com/docs/api-reference/chat/create#chat-create-logprobs) ko'rsatadi. U avval foydalanuvchi tomonidan taqdim etilgan ixtiyoriy matnning _logprobs_'larini olishga imkon berardi, ammo [2023-yil sentabrda](https://x.com/xuanalogue/status/1707757449900437984) buni to'xtatdi. "Anthropic" o'z modellarining _logprobs_'larini oshkor qilmaydi.

[^28]: Pullik model _API_'lari ko'pincha chiqish tokenlari soni bo'yicha haq oladi.

[^29]: Bir xil kirish uchun bir nechta natija generatsiya qilish xarajatini kamaytirish uchun qilinadigan ishlar bor. Masalan, kirish faqat bir marta qayta ishlanishi va barcha natijalar uchun qayta ishlatilishi mumkin.

[^30]: Ushbu kitob yozilayotgan vaqtda, "OpenAI" _API_'sida siz [`best_of`](https://platform.openai.com/docs/api-reference/completions/create#completions-create-best_of) parametrini ma'lum bir qiymatga, aytaylik 10 ga, o'rnatib, "OpenAI" modellaridan 10 xil natija orasidan eng yuqori o'rtacha logprob'ga ega bo'lganini qaytarishni so'rashingiz mumkin.

[^31]: [Wang va boshqalar (2023)](https://arxiv.org/abs/2203.11171) bu yondashuvni o'z-o'ziga muvofiqlik (`self-consistency`) deb atashgan.

[^32]: Biroq, mo'rt model bilan qilinadigan eng optimal ish — uni boshqasiga almashtirishdir.

[^33]: Ushbu kitob yozilayotgan vaqtda, dastur va modelga qarab, to'g'ri generatsiya qilingan _JSON_ obyektlarining foizini 0% dan to 90% larning yuqorisigacha bo'lgan oraliqda ko'rdim.

[^34]: Modelni noldan kerakli formatga rioya qiladigan ma'lumotlarda o'qitish ham ishlaydi, ammo bu kitob modellarni noldan ishlab chiqish haqida emas.

[^35]: Ba'zi qo'shimcha sozlash xizmatlari buni siz uchun avtomatik ravishda bajaradi. ["OpenAI"ning qo'shimcha sozlash xizmatlari](https://community.openai.com/t/how-to-build-a-conversation-classifier-with-the-new-fine-tuning-job-api-and-gpt3-5/341075) avval o'qitish paytida klassifikator boshi (`classifier head`) qo'shishga imkon berardi, ammo men yozayotgan vaqtda bu xususiyat o'chirib qo'yilgan.

[^36]: Memda aytilganidek, [imkoniyatlar past, lekin hech qachon nolga teng emas](https://x.com/OxfordDiplomat/status/1424388443010998277?lang=en).

[^37]: 2023-yil dekabr oyida men maslahat beradigan bir SI kompaniyasining uch oylik mijozlarni qo'llab-quvvatlash so'rovlarini ko'rib chiqdim va savollarning beshdan bir qismi SI modellarining barqarorsizligi bilan bog'liqligini aniqladim. 2023-yil iyul oyida Drew Houston ("Dropbox" bosh direktori) va Harrison Chase ("LangChain" bosh direktori) bilan ishtirok etgan panelda biz hammamiz gallyutsinatsiya ko'plab korporativ SI qo'llanish holatlari uchun eng katta to'siq ekanligiga amin bo'ldik.