---
title: Model tanlash
description: "Model tanlash ish oqimi: qat'iy va yumshoq atributlar, ochiq manbali vs xususiy modellar, model API vs o'zi ishlatish. Litsenziyalar, ma'lumotlar maxfiyligi, nazorat, xarajat-samaradorlik tahlili. Benchmarklar va reyting jadvallari."
keywords: model tanlash, model selection, model tanlash ish oqimi, model selection workflow, qat'iy atributlar, hard attributes, yumshoq atributlar, soft attributes, ochiq manbali modellar, open-source models, xususiy modellar, proprietary models, model API, o'zi ishlatish, self-hosting, litsenziyalar, licenses, ma'lumotlar maxfiyligi, data privacy, nazorat, control, xarajat-samaradorlik, cost-effectiveness, benchmarklar, benchmarks, reyting jadvallari, leaderboards, SI muhandisligi, AI muhandisligi, sun'iy intellekt muhandisligi
author: Webiston.uz
---

# Model tanlash

Oxir-oqibat, sizni qaysi model eng zo'r ekanligi unchalik qiziqtirmaydi. Sizni qaysi model aynan sizning dasturlaringiz uchun eng yaxshi ekanligi qiziqtiradi. Dasturingiz uchun mezonlarni aniqlab olganingizdan so'ng, siz modellarni aynan shu mezonlar asosida baholashingiz kerak.

Dasturni ishlab chiqish jarayonida, turli moslashtirish texnikalari orqali olg'a siljir ekansiz, model tanlashni qayta-qayta amalga oshirishingizga to'g'ri keladi. Masalan, prompt muhandisligi imkoniyatni baholash uchun umumiy hisobda eng kuchli modeldan boshlanishi, keyin esa kichikroq modellar ham ish berishini tekshirish uchun orqaga qarab yurishi mumkin. Agar siz _finetuning_ qilishga qaror qilsangiz, kodingizni sinab ko'rish uchun kichik modeldan boshlashingiz va keyin qurilmangiz ta'minoti cheklovlariga (masalan, bitta _GPU_'ga) sig'adigan eng katta modelga o'tishingiz mumkin.

Umuman olganda, har bir texnika uchun tanlov jarayoni odatda ikki bosqichni o'z ichiga oladi:

1.  Erishish mumkin bo'lgan eng yaxshi samaradorlikni aniqlash.
2.  Modellarni xarajat-samaradorlik o'qlari bo'ylab joylashtirish va pulingizga arziydigan eng yaxshi samaradorlikni beradigan modelni tanlash.

Biroq, haqiqiy tanlov jarayoni ancha nozikroq. Keling, uning qanday ko'rinishda bo'lishini o'rganamiz.

## Model tanlash ish oqimi

Modellarni ko'rib chiqayotganda, qat'iy atributlar (o'zgartirishingiz imkonsiz yoki amaliy jihatdan mumkin bo'lmagan xususiyatlar) va yumshoq atributlarni (o'zgartirishingiz mumkin bo'lgan va o'zgartirishga tayyor bo'lgan xususiyatlar) farqlash muhimdir.

**Qat'iy atributlar** ko'pincha model provayderlari tomonidan qabul qilingan qarorlar (litsenziyalar, o'qitish ma'lumotlari, model hajmi) yoki sizning o'zingizning siyosatingiz (maxfiylik, nazorat) natijasidir. Ba'zi ishlatilish senariylari uchun qat'iy atributlar potensial modellar ro'yxatini sezilarli darajada qisqartirishi mumkin.

**Yumshoq atributlar** — bu to'g'rilik, toksiklik yoki faktik izchillik kabi takomillashtirilishi mumkin bo'lgan atributlardir. Ma'lum bir atributni qanchalik yaxshilashingiz mumkinligini taxmin qilishda, optimistik bo'lish va realist bo'lish o'rtasidagi muvozanatni topish qiyin bo'lishi mumkin. Menda bir necha dastlabki promptlar uchun modelning to'g'riligi 20% atrofida bo'lgan holatlar bo'lgan. Biroq, vazifani ikki bosqichga ajratganimdan so'ng, to'g'rilik 70% ga sakragan. Shu bilan birga, bir necha hafta sozlashdan keyin ham model mening vazifam uchun yaroqsiz bo'lib qolgan va men o'sha modeldan voz kechishga majbur bo'lgan holatlarim ham bo'lgan.

Nimani qat'iy va nimani yumshoq atribut deb belgilashingiz ham modelga, ham sizning ishlatilish senariyingizga bog'liq. Masalan, agar siz modelni tezroq ishlashi uchun optimallashtirish imkoniga ega bo'lsangiz, kechikish yumshoq atributdir. Agar siz boshqa birovning serverida ishlaydigan modeldan foydalansangiz, u qat'iy atributdir.

Yuqori darajada, baholash ish oqimi to'rt bosqichdan iborat (4-5-rasmga qarang):

1.  Qat'iy atributlari sizga to'g'ri kelmaydigan modellarni saralab tashlash. Sizning qat'iy atributlar ro'yxatingiz ko'p jihatdan o'zingizning ichki siyosatingizga, tijorat _API_'laridan foydalanishni yoki o'z modelingizni ishlatishni xohlashingizga bog'liq.
2.  Tajriba o'tkazish uchun eng istiqbolli modellarni saralab olish maqsadida, ochiq mavjud bo'lgan ma'lumotlardan, masalan, benchmark natijalari va reyting jadvallari reytingidan foydalanish. Bunda model sifati, kechikish va xarajat kabi turli maqsadlarni muvozanatlash kerak.
3.  Eng yaxshi modelni topish uchun o'zingizning shaxsiy baholash jarayonlari ketma-ketligingiz bilan tajribalar o'tkazish. Bu yerda ham barcha maqsadlaringizni muvozanatlash talab etiladi.
4.  Nosozliklarni aniqlash va dasturingizni yaxshilash uchun fikr-mulohazalarni yig'ish maqsadida modelingizni real amaliyotda doimiy ravishda kuzatib borish.

![4-5-rasm. Dasturingiz uchun modellarni baholash bo'yicha baholash ish oqimining umumiy ko'rinishi.](/ai-engineering/4-chapter/4.5-figure.png)

<div className='text-center text-sm italic'>4-5-rasm. Dasturingiz uchun modellarni baholash bo'yicha baholash ish oqimining umumiy ko'rinishi.</div>

Bu to'rt bosqich bir-birini takrorlab turuvchi, ya'ni iterativ jarayondir. Har bir keyingi bosqichda olingan yangi ma'lumotlar sizni avvalgi qadamdagi qaroringizni qayta ko'rib chiqishga undashi mumkin. Tasavvur qiling, siz dastlab ochiq manbali modellarni ishlatishga qaror qildingiz. Biroq, ochiq va xususiy baholashlardan so'ng, ochiq manbali modellar siz kutgan samaradorlik darajasini bera olmasligini anglab yetasiz va natijada tijorat _API_'lariga o'tishga majbur bo'lasiz.

Monitoring va foydalanuvchi fikr-mulohazalarini yig'ish masalalari 10-bobda batafsil ko'rib chiqiladi. Ushbu bobning qolgan qismida esa biz dastlabki uchta bosqichga e'tibor qaratamiz. Ishni aksariyat jamoalar qayta-qayta duch keladigan savoldan boshlaymiz: model _API_'laridan foydalangan ma'qulmi yoki modellarni o'z serverlarida ishlatgan afzalmi? Shundan so'ng, son-sanoqsiz ochiq benchmarklar olamida qanday adashib qolmaslik va nima uchun ularga ko'r-ko'rona ishonib bo'lmasligi haqida so'z yuritamiz. Bu muhokamalar bobning so'nggi, asosiy qismi uchun zamin yaratadi. Zero, ochiq benchmarklarga to'liq tayanish mumkin bo'lmagan sharoitda, siz o'zingiz ishonadigan promptlar va metrikalar asosida shaxsiy baholash jarayonlari ketma-ketligini loyihalashingizga to'g'ri keladi.

## O'zi yaratishmi yoki sotib olishmi?

Har qanday texnologiyadan foydalanishda kompaniyalar uchun doimiy savol — uni o'zi yaratish kerakmi yoki sotib olish kerakmi. Aksariyat kompaniyalar fundamental modellarni noldan yaratmasligi sababli, savol quyidagicha qo'yiladi: tijoriy model _API_'laridan foydalanish kerakmi yoki **ochiq manbali** (_open source_) modelni o'zingiz ishlatishingiz kerakmi. Bu savolning javobi sizning nomzod modellar havzangizni sezilarli darajada qisqartirishi mumkin.

Keling, avval modellar haqida gap ketganda ochiq manbali deganda aynan nimani anglatishini ko'rib chiqamiz, so'ngra bu ikki yondashuvning afzalliklari va kamchiliklarini muhokama qilamiz.

### Ochiq manbali, ochiq parametrli va model litsenziyalari

"**Ochiq manbali model**" atamasi bahsli bo'lib qoldi. Dastlab, bu atama odamlar yuklab olishi va ishlatishi mumkin bo'lgan har qanday modelni anglatardi. Ko'pgina ishlatilish senariylari uchun modelni yuklab olishning o'zi yetarli. Biroq, ba'zi odamlar model samaradorligi asosan u qanday ma'lumotlarda o'qitilganiga bog'liq bo'lgani uchun, model faqat uning o'qitish ma'lumotlari ham ommaga ochiq bo'lgandagina "ochiq" deb hisoblanishi kerak, deb ta'kidlashadi.

Ochiq ma'lumotlar modeldan yanada moslashuvchan foydalanish imkonini beradi, masalan, modelni model arxitekturasi, o'qitish jarayoni yoki o'qitish ma'lumotlarining o'ziga o'zgartirishlar kiritib, noldan qayta o'qitish. Ochiq ma'lumotlar, shuningdek, modelni tushunishni osonlashtiradi. Ba'zi ishlatilish senariylari, shuningdek, audit maqsadlarida o'qitish ma'lumotlariga kirishni talab qiladi, masalan, modelning buzilgan yoki noqonuniy olingan ma'lumotlarda o'qitilmaganiga ishonch hosil qilish uchun.[^10]

Ma'lumotlarning ham ochiq yoki yo'qligini bildirish uchun, ochiq ma'lumotlar bilan birga kelmaydigan modellar uchun **"ochiq parametrli"** (_open weight_) atamasi, ochiq ma'lumotlar bilan birga keladigan modellar uchun esa **"ochiq model"** (_open model_) atamasi ishlatiladi.

<Callout>
#### Eslatma

Ba'zi odamlar "**ochiq manbali**" atamasi faqat to'liq ochiq modellar uchun saqlanishi kerak, deb ta'kidlashadi. Ushbu kitobda, soddalik uchun, men **ochiq manbali** deganda, o'qitish ma'lumotlarining mavjudligi va litsenziyalaridan qat'i nazar, parametrlari (_weights_) ommaga ochiq bo'lgan barcha modellarni nazarda tutaman.
</Callout>

Ushbu kitob yozilayotgan vaqtda, ochiq manbali modellarning aksariyati faqat ochiq parametrli (_open weight_) hisoblanadi. Model yaratuvchilari o'qitish ma'lumotlarini ataylab yashirishlari mumkin, chunki bu ma'lumotlar ularni jamoatchilik tanqidi va ehtimoliy sud da'volariga duchor qilishi mumkin.

Ochiq manbali modellarning yana bir muhim atributi — bu ularning litsenziyalaridir. Fundamental modellardan oldin ham, `MIT`, `Apache 2.0`, _GNU General Public License_ (`GPL`), `BSD` (_Berkely Software Distribution_), `Creative Commons` va hokazo kabi turli xil litsenziyalar bilan ochiq manbalilik dunyosi yetarlicha chalkash edi. Ochiq manbali modellar litsenziyalash vaziyatini yanada yomonlashtirdi. Ko'pgina modellar o'zlarining noyob litsenziyalari ostida chiqariladi. Masalan, Meta `Llama 2`'ni [Llama 2 Community License Agreement](https://ai.meta.com/llama/license/) ostida va `Llama 3`'ni [Llama 3 Community License Agreement](https://www.llama.com/llama3/license/) ostida chiqardi. Hugging Face o'zining `BigCode` modelini [BigCode Open RAIL-M v1](https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement) litsenziyasi ostida chiqardi. Biroq, umid qilamanki, vaqt o'tishi bilan hamjamiyat ba'zi standart litsenziyalarga yaqinlashadi. Google'ning [`Gemma`](https://github.com/google-deepmind/gemma/blob/main/LICENSE) va [`Mistral-7B`](https://huggingface.co/docs/transformers/en/model_doc/mistral#license) modellari ham `Apache 2.0` litsenziyasi ostida chiqarildi.

Har bir litsenziyaning o'z shartlari bor, shuning uchun har bir litsenziyani o'z ehtiyojlaringiz uchun baholash sizga bog'liq. Biroq, mana, menimcha, har kim so'rashi kerak bo'lgan bir nechta savollar:

- **Litsenziya tijorat maqsadlarida foydalanishga ruxsat beradimi?** Meta'ning birinchi `Llama` modeli chiqqanda, u [notijorat litsenziyasi](https://ai.meta.com/blog/large-language-model-llama-meta-ai/) ostida edi.
- **Agar u tijorat maqsadlarida foydalanishga ruxsat bersa, biror cheklovlar bormi?** `Llama-2` va `Llama-3` litsenziyalari oylik 700 milliondan ortiq faol foydalanuvchiga ega bo'lgan dasturlar Meta'dan maxsus litsenziya talab qilishini belgilaydi.[^11]
- **Litsenziya model natijalaridan boshqa modellarni o'qitish yoki takomillashtirish uchun foydalanishga ruxsat beradimi?** Mavjud modellar tomonidan generatsiya qilingan sintetik ma'lumotlar kelajakdagi modellarni o'qitish uchun muhim ma'lumot manbaidir (8-bobda boshqa ma'lumotlar sintezi mavzulari bilan birga muhokama qilinadi). Ma'lumotlar sintezining ishlatilish senariylaridan biri — bu model distillatsiyasi (_model distillation_): shogirdga (odatda ancha kichikroq model) ustozning (odatda ancha kattaroq model) xulq-atvorini taqlid qilishni o'rgatish. Mistral dastlab bunga ruxsat bermagan, ammo keyinroq o'z [litsenziyasini](https://x.com/arthurmensch/status/1734470462451732839) o'zgartirgan. Ushbu kitob yozilayotgan vaqtda, `Llama` litsenziyalari hali ham bunga ruxsat bermaydi.[^12]

Ba'zi odamlar cheklangan litsenziyalarga ega bo'lgan ochiq manbali modellarni nazarda tutib, "cheklangan parametrli" (_restricted weight_) atamasini ishlatishadi. Biroq, men bu atamani noaniq deb bilaman, chunki barcha oqilona litsenziyalarda cheklovlar mavjud (masalan, siz modeldan genotsid sodir etish uchun foydalana olmasligingiz kerak).

### Ochiq manbali modellar va model _API_'larini taqqoslash

Model foydalanuvchilar uchun ochiq bo'lishi uchun, biror qurilma uni o'zida ishga tushirib, xizmat ko'rsatishi kerak. Modelni ishlatadigan, foydalanuvchi so'rovlarini qabul qiladigan, so'rovlar uchun javoblar generatsiya qilish uchun modelni ishga tushiradigan va bu javoblarni foydalanuvchilarga qaytaradigan xizmat _inference_ xizmati (_inference service_) deb ataladi. Foydalanuvchilar ishlaydigan interfeys esa model _API_'si deb ataladi (4-6-rasm). Model _API_'si atamasi odatda _inference_ xizmatining _API_'sini anglatadi, ammo boshqa model xizmatlari uchun ham _API_'lar mavjud, masalan, _finetuning_ _API_'lari va baholash _API_'lari. 9-bobda _inference_ xizmatlarini qanday optimallashtirish muhokama qilinadi.

![4-6-rasm. Inference xizmati modelni ishga tushiradi va foydalanuvchilarga modelga kirish uchun interfeys taqdim etadi.](/ai-engineering/4-chapter/4.6-figure.png)

<div className='text-center text-sm italic'>4-6-rasm. _Inference_ xizmati modelni ishga tushiradi va foydalanuvchilarga modelga kirish uchun interfeys taqdim etadi.</div>

Modelni ishlab chiqqandan so'ng, ishlab chiquvchi uni ochiq manbali qilishni, _API_ orqali ochiq qilishni yoki ikkalasini ham tanlashi mumkin. Ko'plab model ishlab chiquvchilari ayni paytda model xizmatlari provayderlari hamdir. Cohere va Mistral ba'zi modellarni ochiq manbali qiladi va ba'zilari uchun _API_'lar taqdim etadi. OpenAI odatda o'zining tijoriy modellar bilan tanilgan, ammo ular ham ochiq manbali modellar chiqargan (`GPT-2`, `CLIP`). Odatda, model provayderlari zaifroq modellarni ochiq manbali qiladi va o'zlarining eng yaxshi modellarini pullik devorlar (_paywalls_) ortida, yo _API_'lar orqali, yo o'z mahsulotlarini quvvatlantirish uchun saqlaydi.

Model _API_'lari model provayderlari (OpenAI va Anthropic kabi), bulut xizmatlari provayderlari (Azure va GCP [Google Cloud Platform] kabi) yoki uchinchi tomon _API_ provayderlari (Databricks Mosaic, Anyscale va hokazo) orqali mavjud bo'lishi mumkin. Bir xil model turli xil xususiyatlar, cheklovlar va narxlar bilan turli _API_'lar orqali mavjud bo'lishi mumkin. Masalan, `GPT-4` ham OpenAI, ham Azure _API_'lari orqali mavjud. Turli _API_'lar orqali taqdim etilgan bir xil modelning samaradorligida biroz farqlar bo'lishi mumkin, chunki turli _API_'lar ushbu modelni optimallashtirish uchun turli texnikalardan foydalanishi mumkin, shuning uchun model _API_'lari o'rtasida o'tishda puxta testlar o'tkazganingizga ishonch hosil qiling.

Tijoriy modellar faqat ularning ishlab chiquvchilari tomonidan litsenziyalangan _API_'lar orqali ochiqdir.[^13] Ochiq manbali modellar esa istalgan _API_ provayderi tomonidan qo'llab-quvvatlanishi mumkin, bu sizga o'zingiz uchun eng yaxshi ishlaydigan provayderni tanlash imkonini beradi. Tijoriy model provayderlari uchun modellar ularning raqobatbardosh ustunligidir. O'z modellariga ega bo'lmagan _API_ provayderlari uchun esa, _API_'lar ularning raqobatbardosh ustunligidir. Bu shuni anglatadiki, _API_ provayderlari yaxshiroq narxlar bilan yaxshiroq _API_'lar taklif qilishga ko'proq intilishi mumkin.

Kattaroq modellar uchun miqyoslanadigan _inference_ xizmatlarini yaratish oson ish bo'lmagani uchun, ko'plab kompaniyalar ularni o'zlari yaratishni xohlamaydi. Bu ochiq manbali modellar ustiga qurilgan ko'plab uchinchi tomon _inference_ va _finetuning_ xizmatlarining yaratilishiga olib keldi. `AWS`, `Azure` va `GCP` kabi yirik bulut provayderlarining barchasi ommabop ochiq manbali modellarga _API_ orqali kirishni ta'minlaydi. Ko'plab startaplar ham xuddi shunday qilmoqda.

<Callout>
#### Eslatma

Shuningdek, o'z xizmatlarini sizning xususiy tarmoqlaringiz ichida joriy eta oladigan tijorat _API_ provayderlari ham mavjud. Ushbu muhokamada men bu xususiy joriy etilgan tijorat _API_'lariga mustaqil ishlatadigan modellar kabi munosabatda bo'laman.
</Callout>

Modelni o'zingiz ishlatish yoki model _API_'sidan foydalanish haqidagi savolning javobi ishlatilish senariysiga bog'liq. Shuningdek, bir xil ishlatilish senariysi vaqt o'tishi bilan o'zgarishi mumkin. Ushbu, ko'rib chiqilishi kerak bo'lgan yettita yo'nalish: ma'lumotlar maxfiyligi, ma'lumotlar shajarasi, samaradorlik, funksionallik, xarajatlar, nazorat va qurilmada joriy etish.

#### Ma'lumotlar maxfiyligi

Ma'lumotlarini tashkilot tashqarisiga chiqara olmaydigan va maxfiylikka oid qat'iy siyosatga amal qiladigan kompaniyalar uchun tashqi provayderlar tomonidan taqdim etiladigan model _API_'laridan foydalanish mutlaqo nomaqbuldir.[^14] Bunga yorqin misollardan biri sifatida Samsung xodimlarining kompaniyaga tegishli maxfiy ma'lumotlarni `ChatGPT`'ga kiritib, oqibatda tijoriy sirlarni bexosdan fosh qilib qo'ygan holatini keltirish mumkin.[^15] Samsung ushbu ma'lumot sizib chiqishini qanday aniqlagani va fosh bo'lgan axborot kompaniyaga qarshi qay tarzda ishlatilgani noma'lum. Shunga qaramay, voqea shu qadar jiddiy tus olganki, Samsung 2023-yil may oyida `ChatGPT`'dan [foydalanishni taqiqlab qo'ydi](https://www.bloomberg.com/news/articles/2023-05-02/samsung-bans-chatgpt-and-other-generative-ai-use-by-staff-after-leak).

Ba'zi mamlakatlarda muayyan turdagi ma'lumotlarni davlat chegarasidan tashqariga yuborishni taqiqlovchi qonunlar mavjud. Agar model _API_ provayderi bunday mijozlarga xizmat ko'rsatishni istasa, u o'sha mamlakatlar hududida o'z serverlarini o'rnatishiga to'g'ri keladi.

Agar siz model _API_'sidan foydalansangiz, _API_ provayderi sizning ma'lumotlaringizdan o'z modellarini o'qitish uchun foydalanishi xavfi mavjud. Garchi aksariyat model _API_ provayderlari bunday qilmasliklarini da'vo qilishsa-da, ularning siyosati o'zgarishi mumkin. 2023-yil avgust oyida Zoom kompaniyasi o'zining foydalanish shartlarini bildirmasdan o'zgartirgani ma'lum bo'lgach, [jiddiy noroziliklarga](https://techcrunch.com/2023/08/08/zoom-data-mining-for-ai-terms-gdpr-eprivacy/) duch keldi. Yangi shartlarga ko'ra, Zoom foydalanuvchilar tomonidan yaratilgan ma'lumotlardan, jumladan, mahsulotdan foydalanish statistikasi va diagnostika ma'lumotlaridan o'zining _SI_ modellarini o'qitish uchun foydalanish huquqini olgan edi.

Xo'sh, kimningdir sizning ma'lumotlaringizdan o'z modellarini o'qitish uchun foydalanishining nimasi yomon? Bu sohadagi tadqiqotlar hali kam bo'lsa-da, ba'zi ilmiy ishlar _SI_ modellari o'zlarining o'qitish namunalarini "yodlab qolishi" mumkinligini ko'rsatmoqda. Masalan, [Hugging Face kompaniyasining `StarCoder` modeli](https://x.com/dhuynh95/status/1713917852162424915) o'zining o'qitish to'plamining 8 foizini yodlab qolgani aniqlangan. Bunday yodlab qolingan namunalar 5-bobda ko'rsatib o'tilganidek, tasodifan boshqa foydalanuvchilarga sizib chiqishi yoki yomon niyatli shaxslar tomonidan ataylab suiiste'mol qilinishi mumkin.

#### Ma'lumotlarning kelib chiqishi va mualliflik huquqi

Ma'lumotlarning kelib chiqishi va mualliflik huquqi bilan bog'liq xavotirlar kompaniyalarni turli yo'nalishlarga undashi mumkin: ba'zilari ochiq manbali modellarga yuzlanadi, boshqalari xususiy modellarni tanlaydi, ayrimlari esa har ikkisidan ham voz kechadi.

Aksariyat modellar qanday ma'lumotlar asosida o'qitilgani haqida shaffoflik deyarli yo'q. [`Gemini`'ning texnik hisobotida](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf) Google modelning samaradorligi haqida batafsil to'xtalgan, biroq uni o'qitishda ishlatilgan ma'lumotlar haqida “ma'lumotlarni boyitishga jalb qilingan barcha xodimlarga kamida mahalliy yashash uchun yetarli ish haqi to'lanadi” degan jumladan boshqa hech narsa demagan. [OpenAI'ning texnik direktori (_CTO_)](https://x.com/JoannaStern/status/1768306032466428291) o'z modellarini o'qitish uchun qanday ma'lumotlardan foydalanilgani haqidagi savolga qoniqarli javob bera olmadi.

Bundan tashqari, _SI_ sohasidagi Intellektual Mulk (_IP_) qonunchiligi faol rivojlanish bosqichida. Garchi 2024-yilda [AQSh Patent va Savdo Belgilari Idorasi (_USPTO_)](https://www.uspto.gov/subscription-center/2024/uspto-issues-inventorship-guidance-and-examples-ai-assisted-inventions) “_SI_ yordamida yaratilgan ixtirolar to'g'ridan-to'g'ri patentlashdan mahrum etilmaydi” deb aniqlik kiritgan bo'lsa-da, _SI_ ilovasining patentga loyiqligi “innovatsiyaga inson tomonidan qo'shilgan hissa patent olish uchun yetarlicha salmoqli ekanligiga” bog'liq. Shuningdek, agar model mualliflik huquqi bilan himoyalangan ma'lumotlar asosida o'qitilgan bo'lsa va siz bu modeldan o'z mahsulotingizni yaratishda foydalansangiz, o'z mahsulotingizning Intellektual Mulkini himoya qila olishingiz ham dargumon. Faoliyati o'z Intellektual Mulkiga bog'liq bo'lgan ko'plab kompaniyalar, masalan, o'yin va kino studiyalari, _SI_ atrofidagi Intellektual Mulk qonunlariga aniqlik kiritilmaguncha, o'z mahsulotlarini yaratishda [_SI_'dan foydalanishga ikkilanmoqda](https://www.theverge.com/23444685/generative-ai-copyright-infringement-legal-fair-use-training-data) (James Vincent, The Verge, 2022-yil 15-noyabr).

Ma'lumotlarning kelib chiqishi bilan bog'liq xavotirlar ba'zi kompaniyalarni o'qitish ma'lumotlari ommaga e'lon qilingan to'liq ochiq modellarga yuzlanishga undadi. Buning sababi shundaki, bu yondashuv hamjamiyatga ma'lumotlarni tekshirish va ulardan foydalanish xavfsiz ekanligiga ishonch hosil qilish imkonini beradi, degan qarash mavjud. Bu nazariyada qanchalik jozibali eshitilmasin, amalda biror bir kompaniya uchun fundamental modellarni o'qitishda ishlatiladigan ulkan hajmdagi ma'lumotlar to'plamini sinchkovlik bilan tekshirib chiqish deyarli imkonsiz vazifadir.

Aynan shu xavotirlar sababli, ko'plab kompaniyalar buning o'rniga tijoriy modellarni tanlaydi. Ochiq manbali modellar, odatda, tijoriy modellarga qaraganda cheklangan huquqiy resurslarga ega bo'ladi. Agar siz mualliflik huquqini buzadigan ochiq manbali modeldan foydalansangiz, huquqi buzilgan tomon model ishlab chiquvchilarini emas, katta ehtimol bilan aynan sizni sudga beradi. Biroq, agar siz tijoriy modeldan foydalansangiz, model provayderlari bilan imzolaydigan shartnomalaringiz sizni ma'lumotlarning kelib chiqishi bilan bog'liq xatarlardan potensial himoya qilishi mumkin.[^16]

#### Samaradorlik

Turli benchmarklar ochiq manbali va xususiy modellar o'rtasidagi farq qisqarib borayotganini ko'rsatmoqda. 4-7-rasmda `MMLU` benchmarki bo'yicha bu farqning vaqt o'tishi bilan qanday kamayib borayotganini ko'rish mumkin. Ushbu tendensiya ko'pchilikni kun kelib eng kuchli xususiy model bilan bir xil, balki undan ham yaxshiroq ishlaydigan ochiq manbali model paydo bo'lishiga ishonishga undadi.

Men ochiq manbali modellar xususiy modellarga yetib olishini qanchalik istasam-da, mavjud rag'batlantirish tizimi bunga yo'l qo'ymaydi deb o'ylayman. Tasavvur qiling, sizda eng kuchli model bor: siz uni boshqalar foyda ko'rishi uchun ochiq manbali qilarmidingiz yoki undan o'zingiz foyda ko'rishga harakat qilarmidingiz?[^17] Kompaniyalar uchun o'zlarining eng kuchli modellarini _API_'lar ortida saqlab, nisbatan kuchsizroq modellarini ochiq manbali qilish odatiy holdir.

![MMLU benchmarki bo'yicha ochiq manbali va xususiy modellar o'rtasidagi farqning qisqarishi. Muallif: Maxime Labonne.](/ai-engineering/4-chapter/4.7-figure.png)

<div className='text-center text-sm italic'>`MMLU` benchmarki bo'yicha ochiq manbali va xususiy modellar o'rtasidagi farqning qisqarishi. Muallif: Maxime Labonne.</div>

Shu sababli, yaqin kelajakda eng kuchli ochiq manbali model eng kuchli xususiy modellardan ortda qolishi ehtimoli yuqori. Biroq, eng kuchli modellarni talab qilmaydigan ko'plab ishlatilish senariylari uchun ochiq manbali modellar yetarli bo'lishi mumkin.

Ochiq manbali modellarning ortda qolishiga sabab bo'lishi mumkin bo'lgan yana bir omil shuki, tijoriy modellardan farqli o'laroq, ochiq manbali model yaratuvchilari o'z modellarini takomillashtirish uchun foydalanuvchilardan fikr-mulohazalar ololmaydilar. Model ochiq manbali qilinganidan so'ng, uning yaratuvchilari modelning amalda qanday ishlatilayotgani va real sharoitlarda qanchalik yaxshi ishlayotgani haqida hech qanday ma'lumotga ega bo'lmay qoladilar.

#### Funksionallik

Modelni muayyan bir ishlatilish senariysida ishlashi uchun uning atrofida ko'plab qo'shimcha funksional imkoniyatlar yaratilishi kerak. Quyida shunday funksiyalarga bir nechta misollar keltirilgan:

-   **Kengayuvchanlik:** _Inference_ xizmatining ilovangiz yuklamasini (trafikni) maqbul kechikish va xarajatlarni saqlagan holda qo'llab-quvvatlay olishini ta'minlash.

-   **Funksiyalarni chaqirish:** Modelga tashqi vositalardan foydalanish imkoniyatini berish. Bu, 6-bobda muhokama qilinganidek, _RAG_ va agentga asoslangan yondashuvlar uchun juda muhim.

-   **Strukturalashgan natijalar:** Masalan, modellardan natijalarni _JSON_ formatida yaratishni so'rash.

-   **Natijalarni nazorat qilish mexanizmlari:** Yaratilgan javoblardagi xatarlarni kamaytirish, masalan, javoblarda irqchilik yoki jinsiy kamsitish holatlari yo'qligiga ishonch hosil qilish.

Bu funksiyalarning ko'pini amaliyotga tatbiq etish ancha murakkab va ko'p vaqt talab qiladigan jarayon bo'lgani uchun, ko'plab kompaniyalar o'zlariga kerakli funksiyalarni tayyor holatida taqdim etadigan _API_ provayderlariga murojaat qiladi.

Model _API_'sidan foydalanishning salbiy tomoni shundaki, siz _API_ taqdim etadigan funksiyalar bilangina cheklanib qolasiz. Ko'plab ishlatilish senariylari uchun zarur bo'lgan funksiyalardan biri bu _logprobs_ (tokenlarning logarifmik ehtimolliklari)'dir. Ular klassifikatsiya vazifalari, baholash va model xatti-harakatini tahlil qilish uchun juda foydalidir. Biroq, tijoriy model ishlab chiquvchilari boshqalarning _logprobs_'dan foydalanib o'z modellarini qayta yaratishidan (nusxalashidan) qo'rqib, bu ma'lumotni taqdim etishga ikkilanishi mumkin. Aslida, ko'plab model _API_'lari _logprobs_'ni umuman taqdim etmaydi yoki faqat cheklangan qisminigina ochib beradi.

Shuningdek, siz tijoriy modelni faqatgina model provayderi ruxsat bergan taqdirdagina _finetuning_ qila olasiz. Tasavvur qiling, promptlar yordamida model samaradorligini maksimal darajaga olib chiqdingiz va endi uni _finetuning_ qilmoqchisiz. Agar bu model xususiy bo'lsa va model provayderining _finetuning_ _API_'si bo'lmasa, siz buni qila olmaysiz. Biroq, agar u ochiq manbali model bo'lsa, siz ushbu modelda _finetuning_ xizmatini taklif qiladigan biror servis topishingiz yoki buni o'zingiz amalga oshirishingiz mumkin. Yodda tutingki, 7-bobda muhokama qilinganidek, _finetuning_'ning bir necha turlari mavjud, masalan, qisman _finetuning_ va to'liq _finetuning_. Tijoriy model provayderi _finetuning_'ning barcha turlarini emas, balki faqat ayrimlarini qo'llab-quvvatlashi mumkin.

#### _API_ va muhandislik xarajatlarini taqqoslash

Model _API_'lari har bir foydalanish uchun haq oladi, bu esa yuqori yuklamalarda ularning narxi imkonsiz darajada qimmatlashib ketishiga olib kelishi mumkin. Muayyan miqyosga yetganda, _API_'lar tufayli katta mablag' yo'qotayotgan kompaniya o'z modellarini o'zida joylashtirish haqida o'ylab ko'rishi mumkin.[^18]

Biroq, modelni o'z serveringizda joriy etishingiz salmoqli vaqt, malakali mutaxassislar va muhandislik kuchini talab etadi. Siz modelni optimallashtirishingiz, _inference_ xizmatini zaruratga qarab kengaytirishingiz va qo'llab-quvvatlashingiz, shuningdek, modelingiz uchun nazorat mexanizmlarini joriy qilishingiz kerak bo'ladi. _API_'lar qimmat, lekin muhandislik xarajatlari undan ham oshib tushishi mumkin.

Boshqa tomondan olib qaraganda, begona _API_'dan foydalanish ularning _SLA_'siga (xizmat ko'rsatish darajasi to'g'risidagi kelishuv) bog'liqlikni anglatadi. Agar bu _API_'lar ishonchli bo'lmasa — bu holat faoliyatini endi boshlagan startaplarda ko'p uchraydi — siz o'zingizning muhandislik kuchingizni ushbu _API_'ning beqaror ishlashiga qarshi himoya mexanizmlarini yaratishga sarflashingizga to'g'ri keladi.

Umuman olganda, siz foydalanish va sozlash uchun qulay bo'lgan modelni tanlaganingiz ma'qul. Odatda, xususiy modellar bilan ish boshlash va ularni kengaytirish osonroq, lekin ochiq modellarni moslashtirish osonroq bo'lishi mumkin, chunki ularning tarkibiy qismlaridan foydalanish imkoniyati kengroq.

Ochiq yoki xususiy model tanlashingizdan qat'i nazar, ushbu modelning standart _API_'ga amal qilishi muhim, bu esa kelajakda modellarni almashtirishni osonlashtiradi. Ko'pgina model ishlab chiquvchilari o'z modellarini eng mashhur modellarning _API_'siga taqlid qiladigan qilib yaratishga harakat qilishadi. Ushbu matn yozilayotgan vaqtda, ko'plab _API_ provayderlari OpenAI'ning _API_'sidan andoza olmoqda.

Shuningdek, kuchli hamjamiyat tomonidan qo'llab-quvvatlanadigan modellarni tanlaganingiz afzal. Model qanchalik ko'p imkoniyatlarga ega bo'lsa, uning o'ziga xos nozik jihatlari va "qiliqlari" ham shuncha ko'p bo'ladi. Katta foydalanuvchilar hamjamiyatiga ega modelni tanlasangiz, siz duch kelgan har qanday muammoga boshqalar ham allaqachon duch kelgan va ehtimol o'z yechimlarini internetda e'lon qilgan bo'lishi mumkin.[^19]

#### Nazorat, foydalanish imkoniyati va shaffoflik

["a16z"ning 2024-yildagi tadqiqoti](https://a16z.com/generative-ai-enterprise-2024/) shuni ko'rsatadiki, korxonalarning ochiq manbali modellarga qiziqishining ikki asosiy sababi bu — nazorat va moslashtirish imkoniyatidir (4-8-rasmga qarang).

![Korxonalarning ochiq manbali modellarga qiziqish sabablari. Manba: a16z'ning 2024-yildagi tadqiqoti.](/ai-engineering/4-chapter/4.8-figure.png)

<div className='text-center text-sm italic'>Korxonalarning ochiq manbali modellarga qiziqish sabablari. Manba: a16z'ning 2024-yildagi tadqiqoti.</div>

Agar biznesingiz modelga bog'liq bo'lsa, uning ustidan ma'lum darajada nazoratga ega bo'lishni istashingiz tabiiy, va _API_ provayderlari har doim ham siz xohlagan darajadagi nazoratni taqdim etmasligi mumkin. Boshqa birov tomonidan taqdim etiladigan xizmatdan foydalanganda, siz ularning foydalanish shartlariga va so'rovlar limitiga bo'ysunasiz. Siz faqat provayder tomonidan taqdim etilgan imkoniyatlardan foydalana olasiz va shu sababli modelni kerakli tarzda sozlay olmasligingiz mumkin.

Model provayderlari o'z foydalanuvchilarini va o'zlarini potensial sud da'volaridan himoya qilish uchun irqchilikka oid hazillarni aytish yoki real insonlarning suratlarini yaratish kabi so'rovlarni bloklaydigan himoya mexanizmlarini qo'llaydilar. Xususiy modellar bu borada haddan tashqari senzura qilishga moyilroq bo'ladi. Bu himoya mexanizmlari aksariyat ishlatilish senariylari uchun foydali bo'lsa-da, ayrim holatlar uchun cheklovchi omil bo'lishi mumkin. Masalan, agar ilovangiz real yuzlarni yaratishni talab qilsa (masalan, musiqiy klip ishlab chiqarishga yordam berish uchun), real yuzlarni yaratishdan bosh tortadigan model ish bermaydi. Men maslahat beradigan [Convai](https://convai.com/) kompaniyasi 3D muhit bilan muloqotga kirisha oladigan, jumladan, jismlarni ko'tara oladigan 3D _SI_ personajlarini yaratadi. Tijoriy modellar bilan ishlashda ular shunday muammoga duch kelishdiki, modellar doimiy ravishda: _“Sun'iy intellekt modeli sifatida menda jismoniy qobiliyatlar yo'q”_, deb javob qaytaravergan. Oxir-oqibat, Convai ochiq manbali modellarni _finetuning_ qilishga majbur bo'ldi.

Shuningdek, tijoriy modeldan foydalanish imkoniyatini yo'qotish xavfi ham mavjud, agar butun tizimingizni uning atrofida qurgan bo'lsangiz, bu juda jiddiy oqibatlarga olib kelishi mumkin. Siz ochiq manbali modellarda qila olganingiz kabi, tijoriy modelni biror versiyada "muzlatib qo'ya olmaysiz". Tarixiy jihatdan, tijoriy modellar o'zgarishlar, versiyalar va kelgusi rejalar borasida shaffoflikka ega emas. Modellar tez-tez yangilanadi, lekin barcha o'zgarishlar ham oldindan e'lon qilinmaydi yoki umuman e'lon qilinmasligi mumkin. Sizning promptlaringiz kutilmaganda ishlamay qolishi mumkin va siz buning sababini bilmay qolasiz. Oldindan aytib bo'lmaydigan o'zgarishlar, shuningdek, tijoriy modellarni qat'iy tartibga solinadigan sohalardagi ilovalar uchun yaroqsiz qilib qo'yadi. Biroq, menimcha, model o'zgarishlaridagi bu tarixiy shaffoflikning yo'qligi shunchaki tez rivojlanayotgan sohaning bexosdan yuzaga kelgan oqibati bo'lishi mumkin. Umid qilamanki, soha yetuklashgani sari bu holat o'zgaradi.

Afsuski, kamroq uchraydigan, ammo mavjud bo'lgan yana bir holat shuki, model provayderi sizning ishlatilish senariyingizni, sohangizni yoki mamlakatingizni qo'llab-quvvatlashni to'xtatishi mumkin, yoki sizning mamlakatingiz model provayderingiz faoliyatini taqiqlab qo'yishi mumkin, masalan, [Italiya 2023-yilda OpenAI faoliyatini qisqa muddatga taqiqlagan edi](https://www.cnbc.com/2023/04/04/italy-has-banned-chatgpt-heres-what-other-countries-are-doing.html). Shuningdek, model provayderi butunlay bankrot bo'lishi yoki faoliyatini to'xtatishi ham mumkin.

#### Qurilmaning o'zida joriy etish

Agar modelni bevosita qurilmaning o'zida ishga tushirishni maqsad qilgan bo'lsangiz, uchinchi tomon _API_'laridan foydalanish haqida gap bo'lishi ham mumkin emas. Ko'plab ishlatilish senariylarida modelni lokal ravishda ishlatish maqsadga muvofiqdir. Buning sababi, sizning ishlatilish senariyingiz ishonchli internet aloqasi mavjud bo'lmagan hududlarga mo'ljallangan bo'lishi mumkin. Yoki bu maxfiylik bilan bog'liq bo'lishi mumkin: masalan, siz sun'iy intellekt yordamchisiga barcha ma'lumotlaringizdan foydalanishga ruxsat berishni istaysiz, ammo bu ma'lumotlarning qurilmangizdan chiqib ketishini xohlamaysiz. 4-4-jadvalda model _API_'laridan foydalanish va modellarni mustaqil ravishda ishlatishning afzalliklari va kamchiliklari umumlashtirilgan.

| | **Model _API_'laridan foydalanish** | **Modellarni mustaqil ravishda ishlatish** |
|---------------|----------------------|--------------------------|
| **Ma'lumotlar** | • _Ma'lumotlaringizni model provayderlariga yuborishga to'g'ri keladi, bu esa jamoangiz maxfiy axborotni bexosdan fosh qilishiga olib kelishi mumkin_ | • Ma'lumotlaringizni tashqariga yuborish shart emas <br/><br/> • _Ma'lumotlarning kelib chiqishi / o'qitish ma'lumotlarining mualliflik huquqi uchun tekshiruv va nazorat mexanizmlari kamroq_ |
| **Samaradorlik** | • _Eng yuqori samaradorlikka ega model, ehtimol, yopiq manbali bo'ladi_ | • _Eng yaxshi ochiq manbali modellar, ehtimol, tijoriy modellardan biroz ortda qoladi_  |
| **Funksionallik** | • Kengayuvchanlik, funksiyalarni chaqirish, strukturalashgan natijalarni qo'llab-quvvatlash ehtimoli yuqori <br/><br/> __logprobs_'ni taqdim etish ehtimoli past_ | • _Funksiyalarni chaqirish va strukturalashgan natijalar uchun qo'llab-quvvatlash yo'q yoki cheklangan_ <br/><br/> • Klassifikatsiya, baholash va tahlil qilish uchun foydali bo'lgan _logprobs_ va oraliq natijalardan foydalanish mumkin |
| **Xarajatlar** | • _API xarajatlari_ | • _Malakali mutaxassislar, vaqt, optimallashtirish, ishlatish va qo'llab-quvvatlash uchun muhandislik kuchi_ (model hosting xizmatlaridan foydalanish orqali kamaytirilishi mumkin)  |
| **_Finetuning_** | • _Faqat model provayderlari ruxsat bergan modellarni _finetuning_ qila olasiz_  | • Modellarni _finetuning_ qilish, kvantlash va optimallashtirish mumkin (agar ularning litsenziyalari ruxsat bersa), _lekin buni amalga oshirish qiyin bo'lishi mumkin_ |
| **Nazorat, foydalanish imkoniyati va shaffoflik** | • _So'rovlar limiti_ <br/><br/> • _Modeldan foydalanish imkoniyatini yo'qotish xavfi_ <br/><br/> • _Model o'zgarishlari va versiyalarida shaffoflikning yo'qligi_ | • Ochiq manbali modellardagi o'zgarishlarni tekshirish osonroq <br/><br/> • Modelni "muzlatib qo'yib", undan doimiy foydalanishni ta'minlash mumkin, _lekin model _API_'larini yaratish va qo'llab-quvvatlash mas'uliyati o'zingizda bo'ladi_ |
| **Noodatiy vaziyatlar** | _Internet aloqasisiz qurilmada ishlay olmaydi_ | Qurilmada ishlay oladi, _lekin yana, buni amalga oshirish qiyin bo'lishi mumkin_ |


<div className='text-center text-sm italic'>4-4-jadval. Model _API_'laridan foydalanish va modellarni mustaqil ravishda ishlatishning afzalliklari va kamchiliklari (kamchiliklar kursivda berilgan).</div>

Umid qilamizki, har bir yondashuvning afzallik va kamchiliklari sizga tijoriy _API_'dan foydalanish yoki modelni mustaqil ravishda ishlatish borasida qaror qabul qilishingizga yordam beradi. Bu qaror mavjud variantlar doirasini ancha qisqartiradi. Shundan so'ng, ommaga ochiq bo'lgan model samaradorligi ma'lumotlaridan foydalanib, tanlovingizni yanada aniqlashtirishingiz mumkin.

## Ommaviy benchmarklarni tahlil qilish

Modellarning turli qobiliyatlarini baholash uchun mo'ljallangan minglab benchmarklar (standartlashtirilgan sinovlar to'plami) mavjud. Birgina [Google'ning `BIG-bench` (2022)](https://github.com/google/BIG-bench/blob/main/bigbench/benchmark_tasks/README.md) to'plamining o'zida 214 ta benchmark mavjud. _SI_'ning ishlatilish senariylari soni jadal o'sgani sari, benchmarklar soni ham shunga mos ravishda tez sur'atda ko'payib bormoqda. Bundan tashqari, _SI_ modellari takomillashgani sari, eski benchmarklar o'z ahamiyatini yo'qotadi, bu esa yangi benchmarklarni joriy etish zaruratini tug'diradi.

Modelni bir nechta benchmarklar bo'yicha baholashga yordam beradigan vosita _evaluation harness_ (baholash vositalari to'plami) deb ataladi. Ushbu matn yozilayotgan vaqtda, [EleutherAI'ning `lm-evaluation-harness`](https://github.com/EleutherAI/lm-evaluation-harness/blob/master/docs/task_table.md) vositasi 400 dan ortiq benchmarkni qo'llab-quvvatlaydi. [OpenAI'ning `evals`](https://github.com/openai/evals) vositasi esa mavjud 500 ga yaqin benchmarkning istalganini ishga tushirishga va OpenAI modellarini baholash uchun yangi benchmarklarni ro'yxatdan o'tkazishga imkon beradi. Ularning benchmarklari keng qamrovli qobiliyatlarni baholaydi: matematik amallarni bajarish va boshqotirmalarni yechishdan tortib, so'zlarni ifodalovchi _ASCII_ san'atini aniqlashgacha.

### Benchmarklarni tanlash va natijalarni umumlashtirish

Benchmark natijalari ishlatilish senariylaringiz uchun istiqbolli modellarni saralab olishga yordam beradi. Modellarning reytingini tuzish uchun benchmark natijalarini jamlab, umumlashtirish orqali reyting jadvali (leaderboard) yaratiladi. Bu jarayonda ikki muhim savol tug'iladi:

-   Reyting jadvaliga qaysi benchmarklarni kiritish kerak?
-   Modellarning reytingini tuzish uchun bu benchmark natijalarini qanday umumlashtirish kerak?

Mavjud benchmarklarning soni shu qadar ko'pki, ularning barchasini ko'rib chiqishning o'zi imkonsiz, eng yaxshi modelni aniqlash uchun ularning natijalarini umumlashtirish haqida esa gapirmasa ham bo'ladi. Tasavvur qiling, siz kod yaratish vazifasi uchun A va B modellarini solishtirayapsiz. Agar A model kodlashga oid benchmarkda B modeldan yaxshiroq, lekin toksiklik benchmarkida yomonroq natija ko'rsatsa, qaysi birini tanlaysiz? Xuddi shunday, bir model kodlashga oid bitta benchmarkda yaxshiroq, ammo boshqasida yomonroq natija ko'rsatsa, qaysi birini tanlaysiz?

Ommaviy benchmarklar asosida o'z reyting jadvalingizni yaratishda ilhom olish uchun, mavjud ommaviy reyting jadvallarining qanday ishlashini o'rganish foydalidir.

#### Ommaviy reyting jadvallari

Ko'pgina ommaviy reyting jadvallari modellarni ma'lum bir benchmarklar to'plamidagi jamlanma samaradorligiga qarab tartiblaydi. Bu reyting jadvallari juda katta yordam beradi, biroq ularni har tomonlama qamrovli deb bo'lmaydi. Birinchidan, _compute_ (hisoblash quvvatlari) cheklovi tufayli — ya'ni modelni biror benchmarkda baholash uchun hisoblash quvvatlari kerak bo'ladi — aksariyat reyting jadvallari o'z ichiga faqat oz sonli benchmarklarni ola oladi. Ba'zi reyting jadvallari muhim, lekin ko'p resurs talab qiladigan (qimmat) benchmarkni chetlab o'tishi mumkin. Masalan, `HELM` (_Holistic Evaluation of Language Models_) Lite versiyasi uni [ishga tushirish qimmat](https://crfm.stanford.edu/2023/12/19/helm-lite.html) bo'lgani uchun ma'lumot qidirishga oid benchmarkni (`MS MARCO` — _Microsoft Machine Reading Comprehension_) o'z ichiga olmagan. Hugging Face esa [katta hisoblash quvvatlarini](https://discord.com/channels/879548962464493619/922424173916196955/1166444804981399572) talab qilgani sababli `HumanEval`'dan voz kechgan — bu benchmark uchun juda ko'p _completion_ (matnni yakunlash variantlari) yaratish kerak bo'ladi.

[Hugging Face 2023-yilda o'zining Ochiq _LLM_ reyting jadvalini](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard) ilk bor ishga tushirganda, u to'rtta benchmarkdan iborat edi. Yil oxiriga kelib, ular bu sonni oltitaga yetkazishdi. Oz sonli benchmarklar to'plami fundamental modellarning keng qamrovli imkoniyatlari va turli zaif tomonlarini to'liq aks ettirish uchun mutlaqo yetarli emas.

Bundan tashqari, reyting jadvali ishlab chiquvchilari odatda benchmarklarni tanlashga puxta yondashsalar-da, ularning qaror qabul qilish jarayoni foydalanuvchilar uchun har doim ham tushunarli bo'lavermaydi. Turli reyting jadvallari ko'pincha turlicha benchmarklarga ega bo'ladi, bu esa ularning reytinglarini solishtirish va tahlil qilishni qiyinlashtiradi. Masalan, 2023-yil oxirida Hugging Face o'zining Ochiq _LLM_ reyting jadvalini yangilab, modellarni tartiblash uchun oltita turli benchmarkning o'rtacha ko'rsatkichidan foydalanishni boshladi:

-   **`ARC-C` ([Clark va boshq., 2018](https://arxiv.org/abs/1803.05457)):** Boshlang'ich sinf darajasidagi murakkab ilmiy savollarni yechish qobiliyatini o'lchash.

-   **`MMLU` ([Hendrycks va boshq., 2020](https://arxiv.org/abs/2009.03300)):** 57 ta fanni, jumladan, elementar matematika, AQSh tarixi, informatika va huquqni o'z ichiga olgan sohalardagi bilim va mantiqiy fikrlash qobiliyatlarini o'lchash.

-   **`HellaSwag` ([Zellers va boshq., 2019](https://arxiv.org/abs/1905.07830)):** Gapni yoki hikoya/videodagi sahnani yakunlashni prognoz qobiliyatini o'lchash. Maqsad — sog'lom fikr va kundalik faoliyatni tushunishni sinash.

-   **`TruthfulQA` ([Lin va boshq., 2021](https://arxiv.org/abs/2109.07958)):** Modelning faktlarni tushunishiga e'tibor qaratgan holda, nafaqat aniq, balki haqiqatga mos va chalg'itmaydigan javoblar yaratish qobiliyatini o'lchash.

-   **`WinoGrande` ([Sakaguchi va boshq., 2019](https://arxiv.org/abs/1907.10641)):** Til modellari uchun qiyin bo'lishi mo'ljallangan, yuqori darajadagi sog'lom fikrlashni talab qiluvchi, olmoshlarning bog'liqligiga oid murakkab muammolarni yechish qobiliyatini o'lchash.

-   **`GSM-8K` ([Grade School Math, OpenAI, 2021](https://github.com/openai/grade-school-math)):** Boshlang'ich sinf o'quv dasturlarida uchraydigan turli xil matematik masalalarni yechish qobiliyatini o'lchash.

Taxminan o'sha vaqtlarda, [Stanford'ning `HELM` reyting jadvali](https://crfm.stanford.edu/helm/lite/latest/#/leaderboard) o'nta benchmarkdan foydalangan, ulardan faqat ikkitasi (`MMLU` va `GSM-8K`) Hugging Face reyting jadvalida mavjud edi. Qolgan sakkizta benchmark quyidagilar edi:

-   Musobaqa darajasidagi matematika uchun benchmark ([`MATH`](https://arxiv.org/abs/2103.03874))
-   Huquq ([`LegalBench`](https://hazyresearch.stanford.edu/legalbench/)), tibbiyot ([`MedQA`](https://arxiv.org/abs/2009.13081)) va tarjima ([`WMT 2014`](https://huggingface.co/papers/trending)) sohalarining har biri uchun bittadan benchmark
-   O'qib tushunish uchun ikkita benchmark — kitob yoki uzun hikoya asosida savollarga javob berish ([`NarrativeQA`](https://arxiv.org/abs/1712.07040) va [`OpenBookQA`](https://arxiv.org/abs/1809.02789))
-   Umumiy savol-javob uchun ikkita benchmark ([`Natural Questions`](https://research.google/pubs/natural-questions-a-benchmark-for-question-answering-research/), ikki xil shartda: kiritilayotgan ma'lumotda Vikipediya sahifalari bilan va ularsiz)

Hugging Face bu benchmarklarni tanlash sababini shunday izohlagan: "ular turli sohalarda keng qamrovli mantiqiy fikrlash va umumiy bilimlarni sinovdan o'tkazadi".[^20] `HELM` veb-saytida esa ularning benchmarklar ro'yxati Hugging Face reyting jadvalining "soddaligidan ilhomlangani", biroq kengroq doiradagi senariylarni qamrab olishi aytilgan.

Ommaviy reyting jadvallari, umuman olganda, qamrov va benchmarklar soni o'rtasidagi muvozanatni saqlashga harakat qiladi. Ular odatda mantiqiy fikrlash, faktlarga moslik hamda matematika va fan kabi sohaga xos qobiliyatlarni o'z ichiga olgan keng imkoniyatlarni qamrab oladigan kichik bir benchmarklar to'plamini tanlashga intiladi.

Yuzaki qaraganda, bu to'g'ri yondashuvdek tuyuladi. Biroq, "qamrov" nima ekanligi yoki nima uchun u aynan oltita yoki o'nta benchmark bilan cheklanishi haqida aniqlik yo'q. Masalan, nima uchun tibbiyot va huquqqa oid vazifalar `HELM Lite`'ga kiritilgan-u, umumiy fan kiritilmagan? Nima uchun `HELM Lite`'da ikkita matematika testi bor-u, kodlash bo'yicha hech qanday test yo'q? Nega ikkalasida ham matnni qisqartirish, vositalardan foydalanish, toksiklikni aniqlash, rasm qidirish va hokazolar uchun testlar mavjud emas? Bu savollar ommaviy reyting jadvallarini tanqid qilish maqsadida emas, balki modellarni reytinglash uchun benchmarklarni tanlash vazifasi qanchalik murakkab ekanligini ko'rsatish uchun berilmoqda. Agar reyting jadvali ishlab chiquvchilari o'z benchmarklarini tanlash jarayonini tushuntirib bera olmayotgan bo'lsa, buning sababi shunchaki bu ishning haqiqatan ham murakkabligida bo'lishi mumkin.

Benchmark tanlashda ko'pincha e'tibordan chetda qoladigan muhim jihat — bu benchmarklar korrelyatsiyasidir. Bu muhim, chunki agar ikkita benchmark bir-biri bilan to'liq korrelyatsiyada bo'lsa, ularning ikkalasini ham qo'shishning hojati yo'q. Bir-biriga kuchli bog'liq bo'lgan benchmarklar mavjud noxolisliklarni bo'rttirib ko'rsatishi mumkin.[^21]

<Callout>
#### Eslatma

Men ushbu kitobni yozayotgan vaqtda, ko'plab benchmarklar o'z ahamiyatini yo'qotdi yoki yo'qotish arafasida edi. 2024-yil iyun oyida, o'z reyting jadvalining so'nggi yangilanishidan bir yil ham o'tmay, Hugging Face uni yana yangiladi va bu safar ancha qiyinroq hamda amaliyroq qobiliyatlarga e'tibor qaratadigan butunlay yangi benchmarklar to'plamini taqdim etdi. Masalan, [`GSM-8K` o'rniga `MATH lvl 5`](https://x.com/polynoamial/status/1803812369237528825) kiritildi, u musobaqa darajasidagi [`MATH`](https://arxiv.org/abs/2103.03874) benchmarkining eng qiyin savollaridan iborat. `MMLU` esa `MMLU-PRO` ([Wang va boshq., 2024](https://arxiv.org/abs/2406.01574)) bilan almashtirildi. Shuningdek, ular quyidagi benchmarklarni ham qo'shishdi:

-   `GPQA` ([Rein va boshq., 2023](https://arxiv.org/abs/2311.12022)): magistratura darajasidagi savol-javob benchmarki[^22]
-   `MuSR` ([Sprague va boshq., 2023](https://arxiv.org/abs/2310.16049)): fikrlar zanjiriga asoslangan, ko'p bosqichli mantiqiy fikrlash benchmarki
-   `BBH` (`BIG-bench Hard`) ([Srivastava va boshq., 2023](https://arxiv.org/abs/2206.04615)): yana bir mantiqiy fikrlash benchmarki
-   `IFEval` ([Zhou va boshq., 2023](https://arxiv.org/abs/2311.07911)): ko'rsatmalarga amal qilish benchmarki

Shubhasiz, bu benchmarklar ham tez orada o'z ahamiyatini yo'qotadi. Biroq, eskirgan bo'lsa ham, aniq benchmarklarni muhokama qilish, benchmarklarni baholash va tahlil qilish uchun namuna sifatida hali ham foydali bo'lishi mumkin.[^23]
</Callout>

4-5-jadvalda Hugging Face reyting jadvalida qo'llanilgan oltita benchmark o'rtasidagi o'zaro bog'liqlik (korrelyatsiya) ko'rsatkichlari keltirilgan. Bu ko'rsatkichlar 2024-yil yanvar oyida Balázs Galambosi tomonidan hisoblangan. `WinoGrande`, `MMLU` va `ARC-C` benchmarklari bir-biri bilan kuchli bog'liqlikka ega, bu mantiqan to'g'ri, chunki ularning barchasi mantiqiy fikrlash qobiliyatini sinaydi. `TruthfulQA` esa boshqa benchmarklar bilan o'rtacha darajada bog'liq, bu esa modelning mantiqiy fikrlash va matematik qobiliyatlarini yaxshilash uning haqiqatga mosligini har doim ham oshirmasligini ko'rsatadi.

| | `ARC-C` | `HellaSwag` | `MMLU` | `TruthfulQA` | `WinoGrande` | `GSM-8K` |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **`ARC-C`** | 1.0000 | 0.4812 | **0.8672** | 0.4809 | **0.8856** | 0.7438 |
| **`HellaSwag`** | 0.4812 | 1.0000 | 0.6105 | 0.4809 | 0.4842 | 0.3547 |
| **`MMLU`** | 0.8672 | 0.6105 | 1.0000 | 0.5507 | **0.9011** | 0.7936 |
| **`TruthfulQA`** | 0.4809 | 0.4228 | 0.5507 | 1.0000 | 0.4550 | 0.5009 |
| **`WinoGrande`** | **0.8856** | 0.4842 | **0.9011** | 0.4550 | 1.0000 | 0.7979 |
| **`GSM-8K`** | 0.7438 | 0.3547 | 0.7936 | 0.5009 | 0.7979 | 1.0000 |

<div className='text-center text-sm italic'>4-5-jadval. Hugging Face reyting jadvalida qo'llanilgan oltita benchmark o'rtasidagi korrelyatsiya, 2024-yil yanvar oyida hisoblangan.</div>

Modellarni reytinglash uchun tanlangan barcha benchmarklarning natijalari umumlashtirilishi kerak. Ushbu matn yozilayotgan vaqtda, Hugging Face modelning yakuniy reyting ballini olish uchun uning barcha benchmarklardagi natijalarining o'rtacha arifmetigini hisoblaydi. O'rtacha arifmetikni hisoblash barcha benchmark ballarini bir xil deb hisoblashni anglatadi, ya'ni `TruthfulQA` bo'yicha 80% natijaga erishish `GSM-8K` bo'yicha 80% natijaga erishishdan ancha qiyinroq bo'lishi mumkin bo'lsa ham, ikkala 80% lik natijaga bir xil qaraladi. Bu, shuningdek, barcha benchmarklarga bir xil vazn berishni anglatadi, vaholanki, ba'zi vazifalar uchun ishonchlilik boshlang'ich sinf matematik masalalarini yecha olishdan ancha muhimroq bo'lishi mumkin.

[`HELM` mualliflari](https://crfm.stanford.edu/2023/12/19/helm-lite.html) esa, aksincha, o'rtacha arifmetikdan voz kechib, buning o'rniga "o'rtacha g'alaba koeffitsienti"ni tanlashgan. Ular buni "bir modelning boshqa modeldan yaxshiroq natija ko'rsatgan holatlarining senariylar bo'yicha o'rtacha ulushi" deb ta'riflashgan.

Ommaviy reyting jadvallari modellarning umumiy samaradorligi haqida tasavvur olish uchun foydali bo'lsa-da, reyting jadvali aynan qanday qobiliyatlarni o'lchashga harakat qilayotganini tushunish muhim. Ommaviy reyting jadvalida yuqori o'rinni egallagan model, katta ehtimol bilan, lekin har doim ham emas, sizning ilovangiz uchun yaxshi natija ko'rsatadi. Agar sizga kod yaratish uchun model kerak bo'lsa, tarkibida kod yaratish benchmarki bo'lmagan ommaviy reyting jadvali sizga unchalik yordam bera olmasligi mumkin.

#### Ommaviy benchmarklar asosida shaxsiy reyting jadvallarini tuzish

Muayyan bir ilova uchun modellarni baholayotganda, siz aslida modellarni o'zingizning baholash mezonlaringiz asosida tartiblaydigan shaxsiy reyting jadvalini yaratayotgan bo'lasiz. Birinchi qadam — ilovangiz uchun muhim bo'lgan qobiliyatlarni baholaydigan benchmarklar ro'yxatini tuzishdir. Agar kodlash agentini yaratmoqchi bo'lsangiz, kodlashga oid benchmarklarni ko'rib chiqing. Agar yozuvchi yordamchisini yaratsangiz, ijodiy yozishga oid benchmarklarni o'rganing. Yangi benchmarklar doimiy ravishda joriy etilib, eskilarining o'z ahamiyatini yo'qotib borishi sababli, siz eng so'nggi benchmarklarni izlashingiz lozim. Benchmarkning qanchalik ishonchli ekanligini baholashga ishonch hosil qiling. Har kim benchmark yaratishi va e'lon qilishi mumkinligi sababli, ko'plab benchmarklar siz kutgan narsani o'lchamasligi mumkin.

> ##### OpenAI modellarining sifati pasayib boryaptimi?
>
> Har safar OpenAI o'z modellarini yangilaganida, odamlar ularning sifati yomonlashib borayotgandek tuyulayotganidan shikoyat qilishadi. Masalan, Stanford va UC Berkeley ([Chen va boshq., 2023](https://arxiv.org/abs/2307.09009)) tomonidan o'tkazilgan tadqiqot shuni ko'rsatdiki, 4-9-rasmda ko'rsatilganidek, 2023-yil mart va iyun oylari oralig'ida ko'plab benchmarklar bo'yicha ham `GPT-3.5`, ham `GPT-4` modellarining samaradorligi sezilarli darajada o'zgargan.
> 
> ![`GPT-3.5` va `GPT-4` modellarining 2023-yil mart va iyun oylari orasida ayrim benchmarklardagi samaradorligining o'zgarishi (Chen va boshq., 2023).](/ai-engineering/4-chapter/4.9-figure.png)
>
><div className='text-center text-sm italic'>`GPT-3.5` va `GPT-4` modellarining 2023-yil mart va iyun oylari orasida ayrim benchmarklardagi samaradorligining o'zgarishi (Chen va boshq., 2023).</div>
>
> OpenAI ataylab yomonroq modellarni chiqarmaydi deb faraz qilsak, bu kabi tasavvurning sababi nima bo'lishi mumkin? Buning bir ehtimoliy sababi shundaki, baholashning o'zi murakkab va hech kim, hatto OpenAI'ning o'zi ham, model yaxshilanayotganini yoki yomonlashayotganini aniq bilmaydi. Baholash haqiqatan ham murakkab bo'lsa-da, men OpenAI butunlay ko'r-ko'rona harakat qilishiga shubha qilaman.[^24] Agar ikkinchi sabab to'g'ri bo'lsa, bu umuman olganda eng yaxshi model sizning ilovangiz uchun eng yaxshi model bo'lmasligi mumkin degan fikrni yanada mustahkamlaydi.

Barcha modellarning ham hamma benchmarklardagi natijalari ommaga ochiq emas. Agar sizni qiziqtirayotgan modelning siz tanlagan benchmarkdagi natijasi ommaga e'lon qilinmagan bo'lsa, baholashni o'zingiz amalga oshirishingizga to'g'ri keladi.[^25] Yaxshiyamki, bu ishda sizga _evaluation harness_ (baholash vositalari to'plami) yordam berishi mumkin. Benchmarklarni ishga tushirish qimmatga tushishi mumkin. Masalan, Stanford o'zining [to'liq `HELM` to'plamida](https://arxiv.org/abs/2211.09110) 30 ta modelni baholash uchun taxminan \$80,000–\$100,000 sarflagan.[^26] Siz qancha ko'p modelni baholamoqchi bo'lsangiz va qancha ko'p benchmarkdan foydalansangiz, xarajatlar shuncha ortib boradi.

Bir to'plam benchmarklarni tanlab olib, sizni qiziqtirgan modellarning ushbu benchmarklardagi natijalarini qo'lga kiritganingizdan so'ng, modellarni reytinglash uchun bu natijalarni umumlashtirishingiz kerak bo'ladi. Barcha benchmark natijalari ham bir xil o'lchov birligi yoki shkalada bo'lmaydi. Bir benchmark **to'g'rilik**'dan foydalansa, boshqasi `F1` ko'rsatkichidan, yana biri esa `BLEU` bahosidan foydalanishi mumkin. Har bir benchmark siz uchun qanchalik muhim ekanligini o'ylab ko'rishingiz va ularning natijalariga shunga yarasha vazn berishingiz kerak bo'ladi.

Ommaviy benchmarklar yordamida modellarni baholar ekansiz, yodda tutingki, bu jarayonning maqsadi — o'zingizning shaxsiy benchmarklaringiz va metrikalaringiz yordamida yanada chuqurroq tajribalar o'tkazish uchun modellarning kichik bir guruhini saralab olishdir. Buning sababi nafaqat ommaviy benchmarklarning sizning ilovangiz ehtiyojlarini mukammal darajada aks ettira olmasligi, balki ularning katta ehtimol bilan "ifloslangan" (_contaminated_) bo'lishidadir. Ommaviy benchmarklar qanday qilib "ifloslanishi" va ma'lumotlarning "ifloslanishi" bilan qanday kurashish kerakligi keyingi bo'limning mavzusi bo'ladi.

### Ommaviy benchmarklarda ma'lumotlarning ifloslanishi

Ma'lumotlarning ifloslanishi shu qadar keng tarqalgan hodisaki, uning "ma'lumotlarning sizib chiqishi", "test to'plamida o'qitish" yoki shunchaki "firibgarlik" kabi ko'plab nomlari mavjud. Ma'lumotlarning ifloslanishi model o'zi baholanadigan ma'lumotlarning aynan o'zida o'qitilganda yuz beradi. Bunday holda, model shunchaki o'qitish paytida ko'rgan javoblarini yodlab olgan bo'lishi mumkin, bu esa uning baholashda haqqoniy natijasidan yuqoriroq ball to'plashiga olib keladi. Masalan, `MMLU` benchmarkida o'qitilgan model, amalda foydali bo'lmasa-da, yuqori `MMLU` ballarini qo'lga kiritishi mumkin.

Stenford universiteti doktoranti Rylan Schaeffer buni o'zining 2023-yilda chop etilgan [“Pretraining on the Test Set Is All You Need”](https://arxiv.org/abs/2309.08632)(“Test to'plamida dastlabki o'qitish — sizga kerak bo'lgan yagona narsa”) nomli hajviy maqolasida ajoyib tarzda namoyish etgan. Faqatgina bir nechta benchmark ma'lumotlarida o'qitish orqali, uning bir million parametrli modeli deyarli mukammal natijalarga erisha oldi va bu benchmarklarning barchasida o'zidan ancha katta modellardan ustun keldi.

#### Ma'lumotlarning ifloslanishi qanday yuz beradi

Garchi ayrimlar chalg'ituvchi darajada yuqori ballarga erishish uchun benchmark ma'lumotlarida ataylab o'qitishsa-da, aksariyat ma'lumotlarning ifloslanishi bexosdan yuz beradi. Bugungi kunda ko'plab modellar internetdan yig'ilgan (_scraped_) ma'lumotlar asosida o'qitiladi va bu ma'lumot yig'ish jarayoni ommaga ochiq benchmarklardan tasodifan ma'lumotlarni tortib olishi mumkin. Modelni o'qitishdan oldin e'lon qilingan benchmark ma'lumotlari, katta ehtimol bilan, modelning o'qitish ma'lumotlari tarkibiga kirib qolgan bo'ladi.[^27] Mavjud benchmarklarning bunchalik tez o'z ahamiyatini yo'qotishining va model ishlab chiquvchilarining o'z yangi modellarini baholash uchun yangi benchmarklar yaratish zaruratini his qilishlarining sabablaridan biri ham shudir.

Ma'lumotlarning ifloslanishi bilvosita ham yuz berishi mumkin, masalan, baholash va o'qitish ma'lumotlari bir xil manbadan olinganda. Masalan, siz modelning matematik qobiliyatlarini yaxshilash uchun o'qitish ma'lumotlariga matematika darsliklarini kiritishingiz mumkin, boshqa birov esa modelning qobiliyatlarini baholash uchun benchmark yaratishda aynan o'sha darsliklardagi savollardan foydalangan bo'lishi mumkin.

Ma'lumotlarning ifloslanishi yaxshi niyatlarda ataylab ham amalga oshirilishi mumkin. Aytaylik, siz foydalanuvchilaringiz uchun imkon qadar eng yaxshi modelni yaratmoqchisiz. Dastlab, siz modelning o'qitish ma'lumotlaridan benchmark ma'lumotlarini chiqarib tashlaysiz va shu benchmarklar asosida eng yaxshi modelni tanlab olasiz. Biroq, yuqori sifatli benchmark ma'lumotlari modelning samaradorligini oshirishi mumkinligi sababli, siz tanlab olingan eng yaxshi modelingizni foydalanuvchilarga taqdim etishdan oldin uni benchmark ma'lumotlarida o'qitishni davom ettirasiz. Natijada, taqdim etilgan model "ifloslangan" bo'ladi va foydalanuvchilaringiz uni ifloslangan benchmarklarda baholay olmaydilar, lekin bu baribir to'g'ri qaror bo'lishi mumkin.

#### Ma'lumotlarning ifloslanishi bilan ishlash

Ma'lumotlarning ifloslanishining keng tarqalganligi baholash benchmarklarining ishonchliligiga jiddiy putur yetkazadi. Modelning advokatlik imtihonlarida yuqori natija ko'rsatishi uning yuridik maslahat berishga usta ekanligini anglatmaydi. Buning sababi shunchaki ushbu modelning ko'plab advokatlik imtihoni savollarida o'qitilgani bo'lishi mumkin.

Ma'lumotlarning ifloslanishi muammosini hal qilish uchun avval ifloslanishni aniqlash, so'ngra esa ma'lumotlaringizni tozalash kerak. Ifloslanishni _n-gram overlapping_ va _perplexity_ kabi evristik usullar yordamida aniqlash mumkin:

-   **_N-gram overlapping_** (ketma-ket kelgan n-ta so'z yoki belgilardan iborat qismlarning mos tushishi):
    Masalan, agar baholash namunasidagi 13 ta tokendan iborat ketma-ketlik o'qitish ma'lumotlarida ham mavjud bo'lsa, model bu baholash namunasini o'qitish paytida ko'rgan bo'lishi ehtimoli yuqori. Bunday baholash namunasi ifloslangan deb hisoblanadi.

-   **_Perplexity_** (model uchun matnni prognoz qilish qanchalik kutilmagan yoki qiyin ekanligini o'lchovchi ko'rsatkich):
    Eslatma uchun, _perplexity_ model uchun berilgan matnni prognoz qilish qanchalik qiyin ekanligini o'lchaydi. Agar modelning baholash ma'lumotlaridagi _perplexity_'si g'ayrioddiy darajada past bo'lsa, ya'ni model matnni osonlik bilan bashorat qila olsa, model bu ma'lumotni avval o'qitish paytida ko'rgan bo'lishi mumkin.

_N-gram overlapping_ yondashuvi aniqroq, lekin uni ishga tushirish ko'p vaqt talab qiladigan va qimmat bo'lishi mumkin, chunki siz har bir benchmark namunasini butun o'qitish ma'lumotlari bilan solishtirib chiqishingiz kerak. Shuningdek, o'qitish ma'lumotlaridan foydalanish imkoni bo'lmasa, bu usulni qo'llab bo'lmaydi. _Perplexity_ yondashuvi esa unchalik aniq emas, lekin ancha kam resurs talab qiladi.

Ilgari _ML_ darsliklarida baholash namunalarini o'qitish ma'lumotlaridan olib tashlash tavsiya etilardi. Maqsad — turli modellarni solishtirish imkoniyatiga ega bo'lish uchun baholash benchmarklarini standartlashtirilgan holda saqlash edi. Biroq, fundamental modellar davrida aksariyat odamlar o'qitish ma'lumotlarini nazorat qila olmaydi. O'qitish ma'lumotlarini nazorat qila olgan taqdirimizda ham, barcha benchmark ma'lumotlarini olib tashlashni xohlamasligimiz mumkin, chunki yuqori sifatli benchmark ma'lumotlari modelning umumiy samaradorligini oshirishga yordam beradi. Bundan tashqari, modellar o'qitilganidan keyin yaratiladigan benchmarklar doim bo'ladi, shuning uchun ifloslangan baholash namunalari ham doim mavjud bo'ladi.

Model ishlab chiquvchilari orasida keng tarqalgan amaliyot — o'z modellarini o'qitishdan avval, ular uchun muhim bo'lgan benchmarklarni o'qitish ma'lumotlaridan olib tashlashdir. Ideal holda, modelning biror benchmarkdagi samaradorligi haqida hisobot berilganda, ushbu benchmark ma'lumotlarining qancha foizi o'qitish ma'lumotlari tarkibida borligini hamda modelning ham umumiy benchmarkda, ham uning faqat toza (ifloslanmagan) namunalaridagi natijalarini ko'rsatib o'tish maqsadga muvofiqdir. Afsuski, ifloslanishni aniqlash va bartaraf etish zahmat talab qilgani bois, ko'pchilik bu bosqichni shunchaki o'tkazib yuborishni ma'qul ko'radi.

OpenAI `GPT-3`'ning keng tarqalgan benchmarklar bilan ifloslanishini tahlil qilar ekan, o'qitish ma'lumotlari tarkibida kamida 40% qismi mavjud bo'lgan 13 ta benchmarkni aniqladi ([Brown va boshq., 2020](https://arxiv.org/abs/2005.14165)). Faqat toza namunalar yordamida baholash va butun benchmark yordamida baholash o'rtasidagi samaradorlikning nisbiy farqi 4-10-rasmda ko'rsatilgan.

![`GPT-3` samaradorligidagi nisbiy farq: faqat toza namunalar bo'yicha baholash natijalarining butun benchmark bo'yicha baholash natijalariga nisbati.](/ai-engineering/4-chapter/4.10-figure.png)

<div className='text-center text-sm italic'>`GPT-3` samaradorligidagi nisbiy farq: faqat toza namunalar bo'yicha baholash natijalarining butun benchmark bo'yicha baholash natijalariga nisbati.</div>

Ma'lumotlarning ifloslanishiga qarshi kurashish maqsadida, Hugging Face kabi reyting jadvallarini yurituvchilar [keskin farq qiluvchi natijalarni (_outliers_)](https://www.interconnects.ai/p/how-the-open-source-llm-ecosystem) aniqlash uchun modellarning muayyan benchmarkdagi samaradorligining standart og'ishlarini grafikda ko'rsatadilar. Ommaviy benchmarklar o'z ma'lumotlarining bir qismini maxfiy saqlashi va model ishlab chiquvchilariga modellarni ushbu maxfiy, nazorat uchun ajratilgan ma'lumotlar (_private hold-out data_) asosida avtomatik baholash imkonini beradigan vositani taqdim etishi lozim.

Ommaviy benchmarklar yomon modellarni saralab tashlashga yordam beradi, lekin ular sizning ilovangiz uchun eng yaxshi modellarni topishga yordam bermaydi. Ommaviy benchmarklar yordamida nomzodlarni istiqbolli modellar to'plamigacha qisqartirgandan so'ng, ilovangiz uchun eng munosibini topish maqsadida o'zingizning shaxsiy baholash jarayonlar zanjiringizni (_evaluation pipeline_) ishga tushirishingiz kerak bo'ladi. Shaxsiy baholash jarayonlar zanjirini qanday loyihalash keyingi mavzumiz bo'ladi.

### Izohlar

[^10]: O'qitish ma'lumotlarini ochiq qilish uchun yana bir argument shuki, modellar ehtimol jamoatchilik tomonidan yaratilgan internetdan olingan ma'lumotlarda o'qitilgani uchun, jamoatchilik modellarining o'qitish ma'lumotlariga kirish huquqiga ega bo'lishi kerak.

[^11]: Ruhan, bu cheklov [Elastic litsenziyasiga](https://www.elastic.co/licensing/elastic-license) o'xshaydi, u kompaniyalarga Elastic'ning ochiq manbali versiyasini o'z serverida ishga tushirishga qilingan xizmat sifatida taklif qilishni va Elasticsearch platformasi bilan raqobatlashishni taqiqlaydi.

[^12]: Modelning litsenziyasi ruxsat bersa ham, uning natijasidan boshqa modellarni yaxshilash uchun foydalanib bo'lmasligi mumkin. `ChatGPT` natijalarida o'qitilgan X modelini ko'rib chiqaylik. X'ning bunga ruxsat beruvchi litsenziyasi bo'lishi mumkin, lekin agar `ChatGPT`'da bo'lmasa, unda X `ChatGPT`'ning foydalanish shartlarini buzgan bo'ladi va shuning uchun X'dan foydalanib bo'lmaydi. Shu sababli modelning ma'lumotlar shajarasini (_data lineage_) bilish juda muhim.

[^13]: Masalan, ushbu kitob yozilayotgan vaqtda, siz `GPT-4` modellariga faqat OpenAI yoki Azure orqali kira olasiz. Ba'zilar OpenAI'ning xususiy modellari ustiga xizmatlar ko'rsata olish Microsoft'ning OpenAI'ga sarmoya kiritishining asosiy sabablaridan biri, deb ta'kidlashi mumkin.

[^14]: Qizig'i shundaki, ma'lumotlar maxfiyligiga qat'iy talablarga ega bo'lgan ba'zi kompaniyalar menga aytishicha, garchi ular odatda uchinchi tomon xizmatlariga ma'lumot yubora olmasalar ham, ular o'z ma'lumotlarini `GCP`, `AWS` va `Azure`'da joylashtirilgan modellarga yuborishga rozidirlar. Bu kompaniyalar uchun ma'lumotlar maxfiyligi siyosati ko'proq qaysi xizmatlarga ishonishlari mumkinligi haqida. Ular yirik bulut provayderlariga ishonishadi, lekin boshqa startaplarga ishonishmaydi.

[^15]: Bu voqea bir nechta nashrlar, jumladan, TechRadar tomonidan xabar qilingan (qarang: [“Samsung Workers Made a Major Error by Using ChatGPT”](https://www.techradar.com/news/samsung-workers-leaked-company-secrets-by-using-chatgpt), Lewis Maddison (2023-yil aprel)).

[^16]: Dunyo bo'ylab qoidalar rivojlanib borayotgani sababli, modellar va o'qitish ma'lumotlarining tekshiriladigan axborotiga bo'lgan talablar ortishi mumkin. Tijoriy modellar sertifikatlar taqdim eta olishi va kompaniyalarni bu harakatdan qutqarishi mumkin.

[^17]: Foydalanuvchilar modellarning ochiq manbali bo'lishini xohlashadi, chunki ochiqlik ko'proq ma'lumot va ko'proq imkoniyatlarni anglatadi, lekin bundan model yaratuvchilariga nima foyda? Ko'pgina kompaniyalar _inference_ va _finetuning_ xizmatlarini taqdim etish orqali ochiq manbali modellardan foyda ko'rish uchun paydo bo'ldi. Bu yomon narsa emas. Ko'p odamlar ochiq manbali modellardan foydalanish uchun bu xizmatlarga muhtoj. Ammo, model yaratuvchilari nuqtai nazaridan, nega faqat boshqalar pul ishlashi uchun modellarni yaratishga millionlab, balki milliardlab sarmoya kiritish kerak? Meta ochiq manbali modellarni faqat o'z raqobatchilarini (Google, Microsoft/OpenAI) jilovlab turish uchun qo'llab-quvvatlaydi, deb ta'kidlash mumkin. Ham Mistral, ham Cohere'ning ochiq manbali modellari bor, lekin ularning _API_'lari ham bor. Qaysidir nuqtada, Mistral va Cohere modellari ustiga qurilgan _inference_ xizmatlari ularning raqobatchilariga aylanadi. Ochiq manbali jamiyat uchun yaxshiroq degan argument bor va balki bu rag'bat sifatida yetarlidir. Jamiyat uchun yaxshilikni istaydigan odamlar ochiq manbani ilgari surishda davom etadilar va balki ochiq manbaning g'alaba qozonishiga yordam beradigan yetarli jamoaviy ezgulik bo'lar. Men albatta shunga umid qilaman.

[^18]: API xarajatlaridan eng ko'p zarar ko'radigan kompaniyalar, ehtimol, eng yirik kompaniyalar emas. Eng yirik kompaniyalar xizmat ko'rsatuvchilar uchun qulay shartlarni kelishib olish uchun yetarlicha muhim bo'lishi mumkin.

[^19]: Bu dasturiy ta'minot infratuzilmasidagi hamjamiyat tomonidan keng sinovdan o'tgan eng mashhur vositalardan doimo foydalanish falsafasiga o'xshaydi.

[^20]: Men Hugging Face'ning Discord'ida nima uchun ular ma'lum benchmarklarni tanlaganlari haqida savol berganimda, Lyuis Tanstall ular o'sha paytdagi mashhur modellar ishlatgan benchmarklar tomonidan yo'naltirilganligini [aytdi](https://discord.com/channels/879548962464493619/922424173916196955/1166444804981399572). Hugging Face jamoasiga bunchalik ajoyib darajada javob beruvchanligi va hamjamiyatga qo'shgan ulkan hissalari uchun rahmat.

[^21]: Men ushbu kitobni yozayotganimda, reyting jadvallari o'zlarining benchmark tanlash va jamlash jarayoni haqida ancha shaffofroq bo'lib qolganini mamnuniyat bilan xabar qilaman. O'zlarining yangi reyting jadvalini ishga tushirganda, Hugging Face benchmarklar korrelyatsiyasining [ajoyib tahlilini](https://huggingface.co/spaces/open-llm-leaderboard/blog) (2024) bo'lishdi.

[^22]: Atigi bir necha yil ichida benchmarklar maktab darajasidagi savollardan aspirantura darajasidagi savollarga o'tishi kerak bo'lganini ko'rish ham juda ajoyib, ham qo'rqinchli.

[^23]: O'yin sanoatida tugamaydigan o'yin konsepsiyasi mavjud, unda o'yinchilar mavjud barcha darajalarni o'zlashtirgan sari yangi darajalar protsedurali ravishda generatsiya qilinishi mumkin. Modellar darajasi oshgan sari qiyinroq muammolar protsedurali ravishda generatsiya qilinadigan tugamaydigan benchmark yaratish juda ajoyib bo'lardi.

[^24]: Boshqalarning tajribasi haqida o'qish foydali, ammo latifani universal haqiqatdan ajratib olish o'zimizga bog'liq. Bir xil model yangilanishi ba'zi dasturlarning yomonlashishiga va ba'zilarining yaxshilanishiga olib kelishi mumkin. Masalan, `GPT-3.5-turbo-0301`'dan `GPT-3.5-turbo-1106`'ga o'tish Voiceflow'ning niyatni tasniflash vazifasida [10% pasayishga](https://www.voiceflow.com/pathways/how-much-do-chatgpt-versions-affect-real-world-performance), lekin GoDaddy'ning mijozlarni qo'llab-quvvatlash chatbotida [yaxshilanishga](https://www.godaddy.com/resources/news/llm-from-the-trenches-10-lessons-learned-operationalizing-models-at-godaddy#h-3-prompts-aren-t-portable-across-models) olib keldi.

[^25]: Agar ochiq mavjud ball bo'lsa, ball qanchalik ishonchli ekanligini tekshiring.

[^26]: `HELM` maqolasida umumiy xarajat tijorat _API_'lari uchun 38 000 dollar va ochiq modellar uchun 19 500 _GPU_ soati ekanligi xabar qilingan. Agar bir soatlik _GPU_ narxi 2.15 dan 3.18 dollargacha bo'lsa, umumiy xarajat 80 000–100 000 dollarni tashkil etadi.

[^27]: Bir do'stim hazillashib aytdi: "Benchmark ommaga e'lon qilinishi bilan o'z foydasini yo'qotadi."