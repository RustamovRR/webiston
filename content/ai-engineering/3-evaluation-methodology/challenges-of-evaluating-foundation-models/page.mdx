# Fundamental modellarni baholashdagi qiyinchiliklar

_ML_ modellarini baholash har doim qiyin bo'lgan. Fundamental modellar paydo bo'lishi bilan esa, baholash yanada murakkablashdi. Fundamental modellarni baholash an'anaviy _ML_ modellarini baholashdan ko'ra qiyinroq ekanligining bir nechta sabablari bor.

Birinchidan, SI modellar qanchalik aqlli bo'lib borsa, ularni baholash shunchalik qiyinlashadi. Ko'pchilik birinchi sinf o'quvchisining matematik yechimi noto'g'ri ekanligini ayta oladi. Lekin doktorlik darajasidagi matematik yechim uchun buni qila oladiganlar kam.[^4] Agar kitob xulosasi bema'ni bo'lsa, uning yomon ekanligini aytish oson, lekin xulosa izchil bo'lsa, buni qilish ancha qiyinroq. Xulosa sifatini tekshirish uchun, avval kitobni o'qib chiqishingiz kerak bo'lishi mumkin. Bu bizni bir natijaga olib keladi: murakkab vazifalar uchun baholash ancha ko'p vaqt talab qilishi mumkin. Siz endi javobni shunchaki qanday eshitilishiga qarab baholay olmaysiz. Sizga faktlarni tekshirish, mulohaza yuritish va hatto sohaviy bilimlarni jalb qilish ham kerak bo'ladi.

Ikkinchidan, fundamental modellarning erkin natijali tabiati modelni etalon javoblarga (`ground truths`) solishtirib baholashning an'anaviy yondashuviga putur yetkazadi. An'anaviy _ML_ bilan, aksariyat vazifalar yopiq turdagi (`close-ended`) bo'ladi. Masalan, tasniflash modeli faqat kutilgan toifalar orasidan natija chiqarishi mumkin. Tasniflash modelini baholash uchun siz uning natijalarini kutilgan natijalarga solishtirishingiz mumkin. Agar kutilgan natija X toifasi bo'lsa-yu, modelning natijasi Y toifasi bo'lsa, demak model xato qilgan. Biroq, erkin natijali vazifa uchun, berilgan bir kirish ma'lumotiga juda ko'p to'g'ri javoblar bo'lishi mumkin. Solishtirish uchun to'g'ri natijalarning to'liq ro'yxatini tuzishning iloji yo'q.

Uchinchidan, aksariyat fundamental modellar "qora quti" sifatida ko'riladi, bunga sabab yo model provayderlari model tafsilotlarini oshkor qilmaslikni tanlagani, yoki dastur yaratuvchilarida ularni tushunish uchun tajriba yetishmasligidir. Model arxitekturasi, o'qitish ma'lumotlari va o'qitish jarayoni kabi tafsilotlar modelning kuchli va zaif tomonlari haqida ko'p narsani ochib berishi mumkin. Bu tafsilotlarsiz, siz modelni faqat uning natijalarini kuzatish orqali baholay olasiz.

Ayni paytda, ochiq mavjud bo'lgan baholash benchmarklari fundamental modellarni baholash uchun yetarli emasligi isbotlandi. Ideal holatda, baholash benchmarklari model imkoniyatlarining to'liq doirasini qamrab olishi kerak. SI rivojlangani sari, benchmarklar ham yetib olish uchun rivojlanishi kerak. Agar model mukammal ballga erishsa, benchmark o'sha model uchun "to'yingan" bo'ladi. Fundamental modellar bilan, benchmarklar tez to'yinmoqda. [`GLUE`](https://arxiv.org/abs/1804.07461) (General Language Understanding Evaluation) benchmarki 2018-yilda chiqdi va atigi bir yilda to'yindi, bu esa 2019-yilda [`SuperGLUE`](https://arxiv.org/abs/1905.00537)ning joriy etilishini taqozo etdi. Xuddi shunday, [`NaturalInstructions`](https://arxiv.org/abs/2104.08773) (2021) [`Super-NaturalInstructions`](https://arxiv.org/abs/2204.07705) (2022) bilan almashtirildi. Ko'plab dastlabki fundamental modellar tayangan kuchli benchmark bo'lgan [`MMLU`](https://arxiv.org/abs/2009.03300) (2020) esa, asosan, [`MMLU-Pro`](https://arxiv.org/abs/2406.01574) (2024) bilan almashtirildi.

Va nihoyat, eng muhimi, umumiy maqsadli modellar uchun baholash doirasi kengaydi. Maxsus vazifali modellar bilan baholash modelning o'zi o'qitilgan vazifadagi samaradorligini o'lchashni o'z ichiga oladi. Biroq, umumiy maqsadli modellar bilan baholash nafaqat modelning ma'lum vazifalardagi samaradorligini baholash, balki model qila oladigan yangi vazifalarni kashf etish haqida hamdir va bular inson imkoniyatlaridan tashqariga chiqadigan vazifalarni ham o'z ichiga olishi mumkin. Baholash SI'ning salohiyati va cheklovlarini o'rganishdek qo'shimcha mas'uliyatni o'z zimmasiga oladi.

Yaxshi xabar shundaki, baholashdagi yangi qiyinchiliklar ko'plab yangi usullar va benchmarklarning paydo bo'lishiga turtki bo'ldi. 3-1-rasmda ko'rsatilishicha, _LLM_ baholashiga oid nashr etilgan maqolalar soni 2023-yilning birinchi yarmida har oy eksponensial ravishda o'sgan — oyiga 2 ta maqoladan deyarli 35 ta maqolagacha.

![3-1-rasm. Vaqt o'tishi bilan LLM'larni baholashga oid maqolalar tendensiyasi.](/ai-engineering/3-chapter/3.1-figure.png)

<div className='text-center text-sm italic'>3-1-rasm. Vaqt o'tishi bilan _LLM_'larni baholashga oid maqolalar tendensiyasi. Rasm [Chang va boshqalar (2023)](https://arxiv.org/abs/2307.03109) ishidan olingan.</div>

GitHub'dagi yulduzchalar soni bo'yicha [eng yaxshi 1000 ta SI bilan bog'liq repozitoriylarni](https://huyenchip.com/llama-police) o'z tahlilimda men baholashga bag'ishlangan 50 dan ortiq repozitoriy topdim (2024-yil may holatiga ko'ra).[^5] Baholash repozitoriylari sonini ularning yaratilish sanasi bo'yicha chizganda, o'sish egri chizig'i eksponensial ko'rinishga ega bo'ladi (3-2-rasm).

Yomon xabar shundaki, baholashga bo'lgan qiziqishning ortishiga qaramay, u SI muhandislik jarayonlari ketma-ketligining qolgan qismiga bo'lgan qiziqishdan ortda qolmoqda. ["DeepMind"dan Balduzzi va boshqalar](https://arxiv.org/abs/1806.02643) o'z maqolalarida ta'kidlaganidek, "baholashlarni ishlab chiqish algoritmlarni ishlab chiqishga nisbatan juda kam bo'lgan tizimli ravishda e'tiborga tushgan." Maqolaga ko'ra, tajriba natijalari deyarli faqat algoritmlarni yaxshilash uchun ishlatiladi va baholashni yaxshilash uchun kamdan-kam ishlatiladi. Baholashga sarmoyalarning yetishmasligini tan olgan holda, ["Anthropic"](https://www.anthropic.com/news/evaluating-ai-systems) siyosatchilarni ham yangi baholash metodologiyalarini ishlab chiqish, ham mavjud baholashlarning mustahkamligini tahlil qilish uchun hukumat moliyalashtirishini va grantlarni oshirishga chaqirdi.

![3-2-rasm. GitHub'dagi 1000 ta eng mashhur SI repozitoriylari orasida ochiq manbali baholash repozitoriylari soni.](/ai-engineering/3-chapter/3.2-figure.png)

<div className='text-center text-sm italic'>3-2-rasm. GitHub'dagi 1000 ta eng mashhur SI repozitoriylari orasida ochiq manbali baholash repozitoriylari soni.</div>

Baholashga qilingan sarmoya SI sohasidagi boshqa yo'nalishlardan qanchalik ortda qolayotganini yanada yaqqolroq ko'rsatish uchun, baholash uchun vositalar soni modellashtirish va o'qitish hamda SI orkestratsiyasi uchun vositalar soniga nisbatan ancha kam (3-3-rasm).

Yetarli sarmoya kiritilmasligi yetarli infratuzilmaning yo'qligiga olib keladi, bu esa odamlarga tizimli baholashlarni amalga oshirishni qiyinlashtiradi. O'zlarining SI dasturlarini qanday baholayotganlari haqida so'ralganda, ko'pchilik menga natijalarni shunchaki ko'z bilan chamalashlarini aytishdi. Ko'pchilikda modellarni baholash uchun ishlatadigan kichik bir "ishonchli" promptlar to'plami bor. Bu promptlarni saralash jarayoni esa tartibsiz (`ad hoc`) bo'lib, odatda dasturning ehtojlariga emas, balki saralovchining shaxsiy tajribasiga asoslanadi. Loyihani boshlashda bu tartibsiz yondashuv bilan bir amallasa bo'lar, lekin dastur iteratsiyasi uchun bu yetarli bo'lmaydi. Ushbu kitobning asosiy maqsadi — baholashga aynan tizimli yondashishni o'rgatishdir.

![3-3-rasm. GitHub'dagi 1000 ta eng mashhur SI repozitoriylari ro'yxatimdan olingan ma'lumotlarga ko'ra, baholash ochiq manbali vositalar soni bo'yicha SI muhandisligining boshqa jihatlaridan ortda qolmoqda.](/ai-engineering/3-chapter/3.3-figure.png)

<div className='text-center text-sm italic'>3-3-rasm. GitHub'dagi 1000 ta eng mashhur SI repozitoriylari ro'yxatimdan olingan ma'lumotlarga ko'ra, baholash ochiq manbali vositalar soni bo'yicha SI muhandisligining boshqa jihatlaridan ortda qolmoqda.</div>

### Izohlar

[^4]: 2024-yil sentabr oyida "OpenAI"ning `GPT-o1` modeli chiqqanda, [Filds medali sohibi Terrens Tao](https://mathstodon.xyz/@tao/113132502735585408) bu model bilan ishlash tajribasini "o'rtamiyona, lekin butunlay qobiliyatsiz bo'lmagan aspirant" bilan ishlashga qiyosladi. Uning taxminicha, SI "qobiliyatli aspirant" darajasiga yetishi uchun yana bir yoki ikki iteratsiya kifoya qilishi mumkin. Uning bahosiga javoban, ko'pchilik hazillashib, agar biz allaqachon SI modellarini baholash uchun eng yorqin insoniy aqllarga muhtoj bo'lgan nuqtaga kelgan bo'lsak, kelajakdagi modellarni baholashga malakali odamimiz qolmaydi, deyishdi.

[^5]: Men "LLM", "GPT", "generative" va "transformer" kalit so'zlari yordamida kamida 500 yulduzchaga ega bo'lgan barcha repozitoriylarni qidirdim. Shuningdek, o'z veb-saytim [https://huyenchip.com](https://huyenchip.com/llama-police) orqali yetishmayotgan repozitoriylar uchun kraudsorsing qildim.